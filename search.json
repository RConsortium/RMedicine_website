[
  {
    "objectID": "Register.html",
    "href": "Register.html",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "The following table lists the registration fees for three categories of attendees: students, academics and members of non-profit organizations, and professionals employed in industry who do not have non-profit status. All prices are in U.S. dollars. Early Bird pricing ends Friday, March 6, 2026.\n\n\n\nCategory\nEarly Bird\nRegular\n\n\n\n\nStudents\n$15\n$30\n\n\nAcademic / Non-profit\n$35\n$50\n\n\nIndustry\n$45\n$70\n\n\n\n\n\n\nA limited number of complimentary registrations are available to enable community members to attend when they would otherwise be unable due to a lack of funding. We place an emphasis on funding applicants who are from historically underrepresented or untapped groups, from low GDP countries, and/or those of lower socioeconomic status.\nTell us why you need one of the limited number of complimentary registrations. Limit 500 characters.\nScholarship application deadline: Friday, April 3rd, 2026\nScholarship award notification: Friday, April 10th, 2026\n\nApply for scholarship"
  },
  {
    "objectID": "Register.html#registration",
    "href": "Register.html#registration",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "The following table lists the registration fees for three categories of attendees: students, academics and members of non-profit organizations, and professionals employed in industry who do not have non-profit status. All prices are in U.S. dollars. Early Bird pricing ends Friday, March 6, 2026.\n\n\n\nCategory\nEarly Bird\nRegular\n\n\n\n\nStudents\n$15\n$30\n\n\nAcademic / Non-profit\n$35\n$50\n\n\nIndustry\n$45\n$70\n\n\n\n\n\n\nA limited number of complimentary registrations are available to enable community members to attend when they would otherwise be unable due to a lack of funding. We place an emphasis on funding applicants who are from historically underrepresented or untapped groups, from low GDP countries, and/or those of lower socioeconomic status.\nTell us why you need one of the limited number of complimentary registrations. Limit 500 characters.\nScholarship application deadline: Friday, April 3rd, 2026\nScholarship award notification: Friday, April 10th, 2026\n\nApply for scholarship"
  },
  {
    "objectID": "Attend.html",
    "href": "Attend.html",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "The R Consortium and its working groups are dedicated to providing a harassment-free experience for participants at all of our events, whether they are held in person or virtually. R Consortium events are working conferences intended for professional networking and collaboration within the open source community. They exist to encourage the open exchange of ideas and expression and require an environment that recognizes the inherent worth of every person and group. While at R Consortium events or related ancillary or social events, any participants, including members, speakers, attendees, volunteers, sponsors, exhibitors, booth staff and anyone else, should not engage in harassment in any form.\nThis Code of Conduct may be revised at any time by The R Consortium and the terms are non-negotiable. Your registration for or attendance at any R Consortium event, whether it’s held in person or virtually, indicates your agreement to abide by this policy and its terms.\n\n\nAll event participants, whether they are attending an in-person event or a virtual event, are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior and applicable laws.\n\n\n\nHarassment will not be tolerated in any form, whether in person or virtually, including, but not limited to, harassment based on sex, gender, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held. Harassment includes the use of abusive, offensive or degrading language, intimidation, stalking, harassing photography or recording, inappropriate physical contact, sexual imagery and unwelcome sexual advances or requests for sexual favors. Any report of harassment at one of our events, whether in person or virtual, will be addressed immediately. Participants asked to stop any harassing behavior are expected to comply immediately. Anyone who witnesses or is subjected to unacceptable behavior should notify a conference organizer at once.\nExhibitors should not use sexualized images, activities, or other material in their booths and must refrain from the use of sexualized clothing, uniforms, costumes, or otherwise creating a sexualized environment. Speakers should not use sexual language, images, or any language or images that would constitute harassment as defined above in their talks.\nIndividuals who participate (or plan to participate) in R Consortium events, whether its an in-person event or a virtual event, should conduct themselves at all times in a manner that comports with both the letter and spirit of this policy prohibiting harassment and abusive behavior, whether before, during or after the event.  This includes statements made in social media postings, on-line publications, text messages, and all other forms of electronic communication.\n\n\n\nIf a participant engages in harassing behavior, whether in person or virtually, the conference organizers may take any action they deem appropriate depending on the circumstances, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nIf a participant (or individual wishing to participate in an R Consortium event, in-person and/or virtual), through postings on social media or other online publications or another form of electronic communication, engages in conduct that violates this policy, whether before, during or after a R Consortium  event, the R Consortium  may take appropriate corrective action, which could include imposing a temporary or permanent ban on an individual’s participation in future R Consortium events, events, working groups, trainings or other activities.\n\n\n\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact a member of the conference staff immediately. You are also encouraged to contact abuse@r-consortium.org.\n\n\n\nOur staff has taken incident response training and responds to harassment reports quickly and thoroughly. As referenced above, if a participant engages in harassing behavior, whether in-person or virtually, the conference organizers may take any action they deem appropriate, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund, depending on the circumstances. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nConference staff will also provide support to victims, including, but not limited to:\n\nProviding an Escort\nContacting Hotel/Venue Security or Local Law Enforcement\nBriefing Key Event Staff For Response/Victim Assistance\nAnd otherwise assisting those experiencing harassment to ensure that they feel safe for the duration of the conference.\n\n\n\n\nIf you are planning to attend an upcoming event, whether in-person or virtually and have concerns regarding another individual who may be present, please contact conduct@r-consortium.org. Precautions will be taken to ensure your comfort and safety, including, but not limited to providing an escort, prepping onsite event staff, keeping victim and harasser from attending the same talks/social events and providing onsite contact cell phone numbers for immediate contact."
  },
  {
    "objectID": "Attend.html#code-of-conduct",
    "href": "Attend.html#code-of-conduct",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "The R Consortium and its working groups are dedicated to providing a harassment-free experience for participants at all of our events, whether they are held in person or virtually. R Consortium events are working conferences intended for professional networking and collaboration within the open source community. They exist to encourage the open exchange of ideas and expression and require an environment that recognizes the inherent worth of every person and group. While at R Consortium events or related ancillary or social events, any participants, including members, speakers, attendees, volunteers, sponsors, exhibitors, booth staff and anyone else, should not engage in harassment in any form.\nThis Code of Conduct may be revised at any time by The R Consortium and the terms are non-negotiable. Your registration for or attendance at any R Consortium event, whether it’s held in person or virtually, indicates your agreement to abide by this policy and its terms.\n\n\nAll event participants, whether they are attending an in-person event or a virtual event, are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior and applicable laws.\n\n\n\nHarassment will not be tolerated in any form, whether in person or virtually, including, but not limited to, harassment based on sex, gender, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held. Harassment includes the use of abusive, offensive or degrading language, intimidation, stalking, harassing photography or recording, inappropriate physical contact, sexual imagery and unwelcome sexual advances or requests for sexual favors. Any report of harassment at one of our events, whether in person or virtual, will be addressed immediately. Participants asked to stop any harassing behavior are expected to comply immediately. Anyone who witnesses or is subjected to unacceptable behavior should notify a conference organizer at once.\nExhibitors should not use sexualized images, activities, or other material in their booths and must refrain from the use of sexualized clothing, uniforms, costumes, or otherwise creating a sexualized environment. Speakers should not use sexual language, images, or any language or images that would constitute harassment as defined above in their talks.\nIndividuals who participate (or plan to participate) in R Consortium events, whether its an in-person event or a virtual event, should conduct themselves at all times in a manner that comports with both the letter and spirit of this policy prohibiting harassment and abusive behavior, whether before, during or after the event.  This includes statements made in social media postings, on-line publications, text messages, and all other forms of electronic communication.\n\n\n\nIf a participant engages in harassing behavior, whether in person or virtually, the conference organizers may take any action they deem appropriate depending on the circumstances, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nIf a participant (or individual wishing to participate in an R Consortium event, in-person and/or virtual), through postings on social media or other online publications or another form of electronic communication, engages in conduct that violates this policy, whether before, during or after a R Consortium  event, the R Consortium  may take appropriate corrective action, which could include imposing a temporary or permanent ban on an individual’s participation in future R Consortium events, events, working groups, trainings or other activities.\n\n\n\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact a member of the conference staff immediately. You are also encouraged to contact abuse@r-consortium.org.\n\n\n\nOur staff has taken incident response training and responds to harassment reports quickly and thoroughly. As referenced above, if a participant engages in harassing behavior, whether in-person or virtually, the conference organizers may take any action they deem appropriate, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund, depending on the circumstances. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nConference staff will also provide support to victims, including, but not limited to:\n\nProviding an Escort\nContacting Hotel/Venue Security or Local Law Enforcement\nBriefing Key Event Staff For Response/Victim Assistance\nAnd otherwise assisting those experiencing harassment to ensure that they feel safe for the duration of the conference.\n\n\n\n\nIf you are planning to attend an upcoming event, whether in-person or virtually and have concerns regarding another individual who may be present, please contact conduct@r-consortium.org. Precautions will be taken to ensure your comfort and safety, including, but not limited to providing an escort, prepping onsite event staff, keeping victim and harasser from attending the same talks/social events and providing onsite contact cell phone numbers for immediate contact."
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n \n\n\n\n\nRichard Hanna & Stephan Kadauke\n\n\nA gentle introduction to R and data science for healthcare professionals and clinical researchers.\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n \n\n\n\n\nCatalina Cañizares & Francisco Cardozo\n\n\nEste taller ofrece una introducción práctica al uso de R para el análisis de datos en investigación médica y en salud. Está dirigido a profesionales de la salud, investigadores clínicos y estudiantes sin experiencia previa en programación. A lo largo del taller, los participantes aprenderán los conceptos básicos de R, cómo trabajar con bases de datos, realizar análisis descriptivos y generar resultados reproducibles.\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n \n\n\n\n\nDaniel D. Sjoberg & Shannon Pileggi\n\n\nAs the pharmaceutical field moves to open-source solutions for reporting on clinical trials, assessing and vetting the options available becomes increasingly important. The {gtsummary} R package is the most widely used tool in the R ecosystem for creating publication-ready summary tables. Its recent integration with the Analysis Results Dataset (ARD) framework represents a major advance for clinical trial reporting. ARDs, which standardize statistical outputs in a machine-readable format, can be robustly generated using the open-source {cards} package developed by Roche, GSK, Novartis, Eli Lilly, Pfizer, and Clymb.\nIn this seminar, attendees will learn about ARDs and how can fit into the larger CDISC-proposed Analysis Results Standard, get hands-on experience using {cards} to build ARDs for both simple and complex statistical summaries, create summary tables using the {gtsummary} package, and learn how utilizing these packages together also makes programmatic quality control of TLGs a simple task.\nLastly, we will review how this ecosystem naturally lends itself to Large Language Models (LLMs). Because {gtsummary} is so widely adopted, LLMs can generate complex {gtsummary} code without additional training. Additionally, LLMs can readily interpret our structured ARDs to assist medical writers summarizing both simple and sophisticated trial results.\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nFrançois Michonneau\n\n\nAs datasets continue to grow in size and complexity, R users increasingly encounter data that exceeds their system’s memory capacity. This hands-on workshop provides practical strategies for efficiently analyzing larger-than-memory datasets using modern open source tools, with a focus on DuckDB and Apache Arrow—all while maintaining familiar tidyverse workflows.\nParticipants will learn when and why to move beyond traditional in-memory data frames, and how to choose the right tool for their specific data challenges. Through a combination of presentation and hands-on exercises, we’ll explore how DuckDB enables SQL-based analytics on large datasets without loading them entirely into memory, and how Arrow provides a high-performance columnar data format for efficient data interchange and processing. We’ll also introduce duckplyr, which brings DuckDB’s performance optimizations directly to your existing dplyr code with minimal syntax changes.\nThe workshop covers essential workflows including reading and querying large CSV and Parquet files, performing aggregations and joins on data that won’t fit in RAM, and leveraging duckplyr to accelerate familiar tidyverse operations on larger datasets. Participants will gain practical experience through real-world examples and learn decision frameworks for selecting appropriate tools based on data size, query patterns, and performance requirements—all without abandoning the tidyverse syntax they already know.\nAttendees should have basic familiarity with R and the tidyverse. By the end of this 3-hour session, participants will be equipped with reproducible techniques to confidently tackle larger datasets in their own research and data analysis workflows.\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nCara Thompson\n\n\nThis workshop is designed for ggplot users who know how to make basic graphs, but want to make them look better and save themselves precious time by building reuseable components. We’ll explore how to choose the right graphs for different aspects of our data story and how to apply a consistent style across them. In doing so, we will focus on making design choices which are accessible, and on making the most of new ggplot2 features. Because getting from a static graph to an interactive one is much easier than most people realise, we’ll finish by exploring how to link two or more interactive graphs together to allow users to explore different aspects of a data story. This is a code-along workshop, so bring your own data and graphs, and we’ll make something fun together!\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nSara Altman\n\n\nLLMs are transforming how we write code, build tools, and analyze data. This workshop will introduce participants to programming with LLM APIs in R using ellmer, an open-source package that makes it easy to work with LLMs from R. We’ll cover the basics of calling LLMs from R, system prompt design, tool calling, and evaluation, and show how to use LLM-powered tools to support common data analysis tasks like exploratory data analysis. Participants will leave with example scripts they can adapt to their own data analysis projects.\n\n\nWorkshop GitHub repo\n\n\n\n\n\n\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nDaniel Chen\n\n\nCOMING SOON\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#r101",
    "href": "workshops.html#r101",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n \n\n\n\n\nRichard Hanna & Stephan Kadauke\n\n\nA gentle introduction to R and data science for healthcare professionals and clinical researchers.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#equidad",
    "href": "workshops.html#equidad",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n \n\n\n\n\nCatalina Cañizares & Francisco Cardozo\n\n\nEste taller ofrece una introducción práctica al uso de R para el análisis de datos en investigación médica y en salud. Está dirigido a profesionales de la salud, investigadores clínicos y estudiantes sin experiencia previa en programación. A lo largo del taller, los participantes aprenderán los conceptos básicos de R, cómo trabajar con bases de datos, realizar análisis descriptivos y generar resultados reproducibles.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#gtsummary",
    "href": "workshops.html#gtsummary",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n \n\n\n\n\nDaniel D. Sjoberg & Shannon Pileggi\n\n\nAs the pharmaceutical field moves to open-source solutions for reporting on clinical trials, assessing and vetting the options available becomes increasingly important. The {gtsummary} R package is the most widely used tool in the R ecosystem for creating publication-ready summary tables. Its recent integration with the Analysis Results Dataset (ARD) framework represents a major advance for clinical trial reporting. ARDs, which standardize statistical outputs in a machine-readable format, can be robustly generated using the open-source {cards} package developed by Roche, GSK, Novartis, Eli Lilly, Pfizer, and Clymb.\nIn this seminar, attendees will learn about ARDs and how can fit into the larger CDISC-proposed Analysis Results Standard, get hands-on experience using {cards} to build ARDs for both simple and complex statistical summaries, create summary tables using the {gtsummary} package, and learn how utilizing these packages together also makes programmatic quality control of TLGs a simple task.\nLastly, we will review how this ecosystem naturally lends itself to Large Language Models (LLMs). Because {gtsummary} is so widely adopted, LLMs can generate complex {gtsummary} code without additional training. Additionally, LLMs can readily interpret our structured ARDs to assist medical writers summarizing both simple and sophisticated trial results.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#big-data",
    "href": "workshops.html#big-data",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n\n\n\n\n\nFrançois Michonneau\n\n\nAs datasets continue to grow in size and complexity, R users increasingly encounter data that exceeds their system’s memory capacity. This hands-on workshop provides practical strategies for efficiently analyzing larger-than-memory datasets using modern open source tools, with a focus on DuckDB and Apache Arrow—all while maintaining familiar tidyverse workflows.\nParticipants will learn when and why to move beyond traditional in-memory data frames, and how to choose the right tool for their specific data challenges. Through a combination of presentation and hands-on exercises, we’ll explore how DuckDB enables SQL-based analytics on large datasets without loading them entirely into memory, and how Arrow provides a high-performance columnar data format for efficient data interchange and processing. We’ll also introduce duckplyr, which brings DuckDB’s performance optimizations directly to your existing dplyr code with minimal syntax changes.\nThe workshop covers essential workflows including reading and querying large CSV and Parquet files, performing aggregations and joins on data that won’t fit in RAM, and leveraging duckplyr to accelerate familiar tidyverse operations on larger datasets. Participants will gain practical experience through real-world examples and learn decision frameworks for selecting appropriate tools based on data size, query patterns, and performance requirements—all without abandoning the tidyverse syntax they already know.\nAttendees should have basic familiarity with R and the tidyverse. By the end of this 3-hour session, participants will be equipped with reproducible techniques to confidently tackle larger datasets in their own research and data analysis workflows.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#ggplot2",
    "href": "workshops.html#ggplot2",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n\n\n\n\n\nCara Thompson\n\n\nThis workshop is designed for ggplot users who know how to make basic graphs, but want to make them look better and save themselves precious time by building reuseable components. We’ll explore how to choose the right graphs for different aspects of our data story and how to apply a consistent style across them. In doing so, we will focus on making design choices which are accessible, and on making the most of new ggplot2 features. Because getting from a static graph to an interactive one is much easier than most people realise, we’ll finish by exploring how to link two or more interactive graphs together to allow users to explore different aspects of a data story. This is a code-along workshop, so bring your own data and graphs, and we’ll make something fun together!\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#llms",
    "href": "workshops.html#llms",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n\n\n\n\n\nSara Altman\n\n\nLLMs are transforming how we write code, build tools, and analyze data. This workshop will introduce participants to programming with LLM APIs in R using ellmer, an open-source package that makes it easy to work with LLMs from R. We’ll cover the basics of calling LLMs from R, system prompt design, tool calling, and evaluation, and show how to use LLM-powered tools to support common data analysis tasks like exploratory data analysis. Participants will leave with example scripts they can adapt to their own data analysis projects.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#r-packages",
    "href": "workshops.html#r-packages",
    "title": "Workshops",
    "section": "",
    "text": "WORKSHOP\n\n\n\n\n\n\n\nDaniel Chen\n\n\nCOMING SOON\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#redcap",
    "href": "workshops.html#redcap",
    "title": "Workshops",
    "section": "R and RedCap Panel Discussion",
    "text": "R and RedCap Panel Discussion\n\n\n\nPANEL\n\n\n\n\n\n\n\nRaymond Balise, Brandon, Rich, others\n\n\nCOMING SOON\n\n\nPre-workshop setup"
  },
  {
    "objectID": "workshops.html#quarto-docs",
    "href": "workshops.html#quarto-docs",
    "title": "Workshops",
    "section": "Building Accessible, On-Brand Documents with Quarto",
    "text": "Building Accessible, On-Brand Documents with Quarto\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nCharlotte Wickham\n\n\nCome see practical strategies for producing Quarto documents that meet organizational standards for both design and accessibility. You’ll learn how to implement consistent organizational branding using brand.yml, plus customization techniques for cases where you need more control. You’ll also learn about recent accessibility improvements for both PDF and HTML outputs.\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "workshops.html#ctrialsgov",
    "href": "workshops.html#ctrialsgov",
    "title": "Workshops",
    "section": "Ctrialsgov R Package",
    "text": "Ctrialsgov R Package\n\n\n\nWORKSHOP\n\n\n\n\n\n\n\nMike Kane\n\n\nCOMING SOON\n\n\nWorkshop GitHub repo"
  },
  {
    "objectID": "Submit.html",
    "href": "Submit.html",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "Please read the details below regarding each submission type prior to completing the submission process.\n\nSUBMIT ABSTRACT\n\n\n\n\nCFP Closes: Friday, March 6th at 11:59 PM ET\nCFP Notifications: Friday, March 20th\nSchedule Announcement: Friday, April 3rd\nPre-Recorded Video Submission: Monday, April 27th\n\n\n\n\nLightning talks (10 min, Thursday May 7th or Friday May 8th)\nRegular talks (20 min, Thursday May 7th or Friday May 8th)\n\nAn abstract proposal should describe a presentation of methodology, a study or project, or an example or case study relevant to one (or more) of our fields of interest, with R-based tools having a substantial role in the work. The content of the presentation should be of interest to the R/Medicine community.\nAvoid sales or marketing pitches and discussion of unlicensed or potentially closed-source technologies in your proposal. Talks of this nature are almost always rejected because they diminish the integrity of our events and are rarely well-received by conference attendees.\nWe do not intend to provide strict instructions on how to prepare your proposal; however, we hope you will review the following guidelines to help you prepare the best submission possible. To get started, here are three questions you should consider before submitting your proposal:\n\nWhat are you hoping to get from your presentation?\nWhat do you expect the audience to gain from your presentation?\nHow will your presentation help better the R Medicine ecosystem?\n\nRemember the questions above when writing your proposal, and think of ways to make it interesting for attendees as you share your experiences, educate the community about a method or an issue, or generate interest in a project.\nAll accepted speakers will be required to pre-record their talk and submit the video by Monday, April 27th.\n\n\n\n\nDemos (1 hour demo of an approach or a package, Monday May 4th) Done live, preferably interactive\nWorkshops (2-3 hours on a topic, Monday May 4th) Detailed instruction on a topic, usually with a website and a repo, participants can choose to code along, include 5-10 min breaks each hour.\n\nTimeslots for workshops and demos are limited, and all will take place on Monday, May 4th. Submissions will require a detailed outline of the planned content, as well as the “run of show” indicating how much time will be spent on instruction, live coding, interactive demo, participant activity, breaks, etc, and in what order, covering the duration of the session. Workshops and demos should be well planned out in advance, and any live demonstration should be thoroughly vetted in advance as well as immediately prior to the session to ensure a seamless experience. Thought must be given to style or presentation, including screen size, font size, colors, and other accessibility issues.\nIn addition, submissions for a demo or workshop will also require a brief 2-3 minute recorded explanation of the demo or workshop, based on the provided abstract and outline.\n\n\n\nR/Medicine has a strong tradition of active discussion in a virtual chat during virtual presentations, and this discussion is much better if the presenter or a co-presenter is active in the chat, sharing relevant links and answering questions during the presentation. If you have relevant links in your presentation, put them in a document ahead of time so that you can easily drop them into the chat when appropriate. If you have a co-presenter, decide who will present and who will chat (or take turns at a natural switching point). All speakers are required to be present during their talk, despite the requirement for pre-recording.\n\n\n\nNote that all talks, demos, and workshops will be recorded and posted to a playlist on the R Consortium’s YouTube channel.\n\n\n\nOne complimentary pass for the event will be provided for the accepted primary speaker and a co-speaker.\n\n\n\nAll speakers are required to adhere to our Code of Conduct.\n\n\n\nWe strongly encourage first-time speakers to submit talks for R/Medicine. We offer an inclusive environment for all levels of presenters, from beginner to expert. If you aren’t sure about your abstract, reach out to us and we will be happy to provide advice on your proposal or review it in advance: rmedicine.conference@gmail.com."
  },
  {
    "objectID": "Submit.html#call-for-proposals",
    "href": "Submit.html#call-for-proposals",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "Please read the details below regarding each submission type prior to completing the submission process.\n\nSUBMIT ABSTRACT\n\n\n\n\nCFP Closes: Friday, March 6th at 11:59 PM ET\nCFP Notifications: Friday, March 20th\nSchedule Announcement: Friday, April 3rd\nPre-Recorded Video Submission: Monday, April 27th\n\n\n\n\nLightning talks (10 min, Thursday May 7th or Friday May 8th)\nRegular talks (20 min, Thursday May 7th or Friday May 8th)\n\nAn abstract proposal should describe a presentation of methodology, a study or project, or an example or case study relevant to one (or more) of our fields of interest, with R-based tools having a substantial role in the work. The content of the presentation should be of interest to the R/Medicine community.\nAvoid sales or marketing pitches and discussion of unlicensed or potentially closed-source technologies in your proposal. Talks of this nature are almost always rejected because they diminish the integrity of our events and are rarely well-received by conference attendees.\nWe do not intend to provide strict instructions on how to prepare your proposal; however, we hope you will review the following guidelines to help you prepare the best submission possible. To get started, here are three questions you should consider before submitting your proposal:\n\nWhat are you hoping to get from your presentation?\nWhat do you expect the audience to gain from your presentation?\nHow will your presentation help better the R Medicine ecosystem?\n\nRemember the questions above when writing your proposal, and think of ways to make it interesting for attendees as you share your experiences, educate the community about a method or an issue, or generate interest in a project.\nAll accepted speakers will be required to pre-record their talk and submit the video by Monday, April 27th.\n\n\n\n\nDemos (1 hour demo of an approach or a package, Monday May 4th) Done live, preferably interactive\nWorkshops (2-3 hours on a topic, Monday May 4th) Detailed instruction on a topic, usually with a website and a repo, participants can choose to code along, include 5-10 min breaks each hour.\n\nTimeslots for workshops and demos are limited, and all will take place on Monday, May 4th. Submissions will require a detailed outline of the planned content, as well as the “run of show” indicating how much time will be spent on instruction, live coding, interactive demo, participant activity, breaks, etc, and in what order, covering the duration of the session. Workshops and demos should be well planned out in advance, and any live demonstration should be thoroughly vetted in advance as well as immediately prior to the session to ensure a seamless experience. Thought must be given to style or presentation, including screen size, font size, colors, and other accessibility issues.\nIn addition, submissions for a demo or workshop will also require a brief 2-3 minute recorded explanation of the demo or workshop, based on the provided abstract and outline.\n\n\n\nR/Medicine has a strong tradition of active discussion in a virtual chat during virtual presentations, and this discussion is much better if the presenter or a co-presenter is active in the chat, sharing relevant links and answering questions during the presentation. If you have relevant links in your presentation, put them in a document ahead of time so that you can easily drop them into the chat when appropriate. If you have a co-presenter, decide who will present and who will chat (or take turns at a natural switching point). All speakers are required to be present during their talk, despite the requirement for pre-recording.\n\n\n\nNote that all talks, demos, and workshops will be recorded and posted to a playlist on the R Consortium’s YouTube channel.\n\n\n\nOne complimentary pass for the event will be provided for the accepted primary speaker and a co-speaker.\n\n\n\nAll speakers are required to adhere to our Code of Conduct.\n\n\n\nWe strongly encourage first-time speakers to submit talks for R/Medicine. We offer an inclusive environment for all levels of presenters, from beginner to expert. If you aren’t sure about your abstract, reach out to us and we will be happy to provide advice on your proposal or review it in advance: rmedicine.conference@gmail.com."
  },
  {
    "objectID": "abstracts.html",
    "href": "abstracts.html",
    "title": "What to Do When Shiny Packages Don’t Fully Support Your Idea",
    "section": "",
    "text": "What to Do When Shiny Packages Don’t Fully Support Your Idea\nShiny is great, but what if you need more flexibility and performance? In this lightning talk, I’ll show how the reactR package helped me extend Shiny’s capabilities to build ESQapp, a highly interactive and scalable application. By integrating React.js, I overcame Shiny’s UI limitations, improved performance, and created custom components that wouldn’t be possible with Shiny alone. If you’re looking to level up your Shiny apps with modern web technologies, this talk is for you!\n\n\n\n\n\n\nIntroduction to medical data harmonisation reporting using R and Quarto\nThere has been an increase of projects that involved data pooling from multiple sources. This is because combining data is an economical way to increase the statistical power of an analysis of a rare outcome that could not be addressed using data from a single project. Prior to statistical or machine learning analysis, a data steward must be able to sort through these heterogeneous inputs and document this process in a coherent way for different stakeholders. This session will show how I create data harmonisation reports using some R packages and Quarto book project. The report will consist of some description to show how a data field will be harmonised, the code that does the harmonisation and suggested outputs in the report to show higher management with limited programming experience that the code works. An R script will also be used to create a pipeline to create many harmonisation reports automatically. Code demonstrations also include how to create validation checks (using pointblank, testthat and collateral) should the dataset changes.\n\n\n\n\n\n\npretestcad: An R package to calculate PreTest Probability (PTP) scores for obstructive Coronary Artery Disease (CAD)\nMost clinicians in cardiology use an online portal such as HeartScore (https://www.escardio.org/Education/Practice-Tools/CVD-prevention-toolbox/HeartScore) to calculate a risk score for a patient. However, as risk scores continue to evolve and update themselves, it can be a tedious process to recalculate the risk score of many patients as these online portal could only do so one patient at a time. As such, there has been a rise of R package dedicated to calculating a patient’s risk of having cardiovascular diseases such as CVrisk (https://cran.r-project.org/web/packages/CVrisk/index.html), RiskScorescvd (https://cran.r-project.org/web/packages/RiskScorescvd/index.html) and whoishRisk (https://github.com/DylanRJCollins/whoishRisk) in an automated way.\nDespite the progress made, pretest risk scores for obstructive CAD is lacking, an R package called pretestcad (https://github.com/JauntyJJS/pretestcad) was made to fill this gap, allowing users to calculate these scores automatically for many patients. Examples of such scores are the 2012 CAD Consortium 2 (CAD2) PTP scores, 2017 PROMISE Minimal-Risk Score and the 2020 Winther et. al. Risk-Factor-weighted Clinical Likelihood (RF-CL) and Coronary Artery Calcium Score-Weighted Clinical Likelihood (CACS-CL) PTP which was recommended to be used in the 2024 ESC Guidelines (https://academic.oup.com/eurheartj/article/45/36/3415/7743115).\nI hope that presenting this R package in this conference could not only raise awareness of the package in the medical field but also collaboration to make the R package more accessible and user friendly and to expand my knowledge of other pretest scores.\n\n\n\n\n\n\nRetrospective clinical data harmonisation reporting using R and Quarto\nThere has been an increase of projects that involved data pooling from multiple sources. This is because combining data is an economical way to increase the statistical power of an analysis of a rare outcome that could not be addressed using data from a single project. Prior to statistical or machine learning analysis, a data steward must be able to sort through these heterogeneous inputs and document this process in a coherent way for different stakeholders. Despite its importance in the big data environment, there are limit resources on how to document this process in a structured, efficient and robust way. This presentation will provide an overview on how I create clinical data harmonisation reports using some R packages and a Quarto book project.\nThe audience in this talk will be able to know the basic framework of creating a Quarto Book or website to document data harmonisation processes, the basic workflow during the data harmonisation process, how to do data validation when writing code for data harmonisation to ensure code workflow is robust to changes in the input data, ways to show to higher management (with limited programming experience) in the harmonisation report that your code works (It is not enough to say that I use test units), able to write an R script to create many data harmonisation reports (One technical report for each cohort pooled and one report that summarised the data harmonisation process for all cohorts).\n\n\n\n\n\n\nMIIPW: An R package for Generalized Estimating Equations with missing data integration using a combination of mean score and inverse probability weighted approaches and multiple imputation\nThe presence of missing values in longitudinal cohort data can lead to inaccuracies in parameter estimation and decreased statistical power. To address this issue, we have developed the MIIPW R package, which incorporates the mean score and inverse probability weighted methods in generalized estimating equations to impute missing scores due to incomplete covariate data. Augmentation of incomplete data in the estimating equation is done through a multiple imputation model. The package employs various methods such as mean score, SIPW, AIPW, miSIPW, and miAIPW to estimate parameters while considering four different covariance structures (AR-1, Exchangeable, Unstructured, and Independent). Additionally, the package uses the QIC for model selection and pays special attention to the calculation of weights within the dataset. The performance of the above mentioned methods has been evaluated through simulation study as well as real data analysis. The MIIPW package is available for download from the comprehensive R archive network and this article provides a practical guide to solve missing data issues. https://CRAN.R-project.org/package=MIIPW\n\n\n\n\n\n\nA framework for cohort building in R: the CohortConstructor package for data mapped to the OMOP Common Data Model\nCohorts are a key concept in epidemiological research, used to identify groups of people who meet specific criteria over a set period based on their clinical records. However, building and managing cohorts in medical data analysis can be complex, often resulting in code that is difficult to review and reuse.\nWhen working with the OMOP Common Data Model (CDM), efforts have been made to define the cohort_table class along with methods and object attributes to facilitate its use. This class is implemented in the omopgenerics R package. The cohort table contains at least four mandatory columns: cohort ID (unique cohort identifier within a cohort table), subject id (unique person identifier), and the cohort start and end dates for each individual.\nAdditionally, cohort objects have four key attributes: 1) Settings - links the cohort ID to its name, 2) Counts - provides the number of subjects and records in each cohort, 3) Attrition - flow chart of excluded records and individuals for each inclusion criteria, and 4) Code lists - stores clinical concept lists used to define cohort entry, exclusion, or exit. These attributes ensure transparency in cohort creation, facilitate validation, and enable easy dissemination of study results.\nTo streamline cohort building in R using OMOP data, we developed the R package CohortConstructor. It provides tools for cohort manipulation, including filtering by demographics, calendar time, or presence/absence in other cohorts. Additionally, the package tracks clinical codes used and population attrition for each operation.\nCohortConstructor version 0.3.5 is available in CRAN at the time of abstract submission. The development version is publicly available in GitHub: https://github.com/OHDSI/CohortConstructor/.\nThe pipeline to build cohorts begins by creating base cohorts. These can be defined using clinical concepts (e.g., asthma diagnoses) or demographics (e.g., females aged &gt;18). Once base cohorts are established, curation steps are applied to meet study-specific inclusion criteria.\nThe curation functions cover the most usual operations in cohort studies, as well as more complex cohort manipulations. These functions can be grouped into three categories: 1) Requirement and Filtering – demographic restrictions, event presence/absence conditions, or filtering specific records, 2) Time Manipulation – adjusting entry and exit dates to align with study periods, observation windows, or key events, and 3) Transformation and Combination – Merging, stratifying, collapsing, matching, or intersecting cohorts.\nCohortConstructor enables researchers to efficiently build and refine cohorts using validated, and reusable code lists. Its user-friendly interface allows both data scientists and epidemiologists to review and apply study-specific criteria with ease. Additionally, tracking attrition throughout the process enhances cohort validation and supports research dissemination.\nIn our demo we will demonstrate the use of the package on synthetic data that the audience can also download and run locally. We will show how a variety of patient cohorts can be identified using the package, and how these can then be used as the foundation for subsequent data analyses. In addition, we will explain how the package works behind the scenes so that it works efficiently on big data and across different database management platforms.\n\n\n\n\n\n\nriskcalc.org: A Repository of Risk Calculators for Medical Decision Making\nriskcalc.org is a repository of clinical risk calculators for medical decision making. In this talk, we provide an overview of the platform, how it is used, and a look at how open-source tools such as Shiny and Shiny Server are used to facilitate its functionality. Finally, we discuss some areas potentially in store for future development.\n\n\n\n\n\n\nnonprobsvy – An R package for modern methods for non-probability survey\nI present nonprobsvy – an package for inference based on non-probability samples. The package implements various approaches that can be categorized into three groups: prediction-based approach, inverse probability weighting, and doubly robust approach. In the package, we assume the existence of either population-level data or probability-based population information and leverage the survey package for inference. The package implements both analytical and bootstrap variance estimation for all of the proposed estimators. In the paper, we present the theory behind the package, its functionalities, and a case study that showcases the usage of the package. The package is aimed at researchers who would like to use non-probability samples (e.g., big data, opt-in web panels, social media) to accurately estimate population characteristics. The package is available on CRAN (https://cran.r-project.org/package=nonprobsvy) and the development version is available at GitHub (http://github.com/ncn-foreigners/nonprobsvy).\n\n\n\n\n\n\nrainbowR: A community for LGBTQ+ folks who code in R\nrainbowR is a community that connects, supports and promotes LGBTQ+ people who code in R and spreads awareness of LGBTQ+ issues through data-driven activism. We run monthly online meet-ups where participants chat and share their R work in a supportive environment. We also organise a buddies scheme, which randomly pairs members of the community, to encourage people to meet and connect. We have a book club, and maintain a repository of queer data sets. We have exciting plans for the future!\nYou’ll learn about what rainbowR does and how you can get involved, whether as a member of the LGBTQ+ community or as an ally, and hopefully forge new connections at the conference and beyond. We believe the whole R community benefits when that community is diverse and inclusive.\n\n\n\n\n\n\nImproving Reproducibility of Medical Research with Controlled Vocabularies\nThe reproducibility of medical research has been a consistently growing topic of interest. Replicating medical research relies on a few key aspects of the original analysis and methodology such as code correctness, documentation, and effective communication of the methods used. A lot of the discussion about reproducibility tends to focus on project setup and configuration such as coding environment, package/library versioning, data access, and study design. However, even when all the above criteria are met, the objective of replicating an analysis still relies on the original work being implemented correctly, clearly documented, and effectively communicated, all of which can be difficult to achieve when restricted by time, budget, and general resource limitations.\nIn this presentation, we introduce a data analysis concept, controlled vocabularies for variable naming, and demonstrate how it can be integrated into medical research. Examples of how a controlled vocabulary can be leveraged to make code correctness, analysis documentation, and methods communication more feasible to achieve will be presented.\nA controlled vocabulary for variable naming allows a user to encode metadata such as time period (e.g. baseline, follow-up), data source (e.g. laboratory results, procedures, diagnoses etc.), event type (e.g. eGFR lab test), data type (e.g. count, numeric, indicator, categorical, date, etc.), unit of measure, and any additional optional pieces of metadata that would be useful to include for a particular project. For example, to document patients in a population who have a record of an eGFR lab test during the baseline period of a study, a potential variable name from a controlled vocabulary for this eGFR indicator variable would be labs_eGFR_baseline_ind. This variable name encodes all relevant information about this variable in the variable name itself.\nThe benefits of encoding this information within the variable names of a project using a defined procedure to name the variables are significant. With a controlled vocabulary defined globally for a project, all variable names will be formatted consistently. This can be particularly helpful during the development process and when debugging code, as the variable names can help a user understand what information should be stored in the column (e.g. if a variable name contains the term num it should be a numeric column). Beyond data wrangling and cleaning, the benefits of having an entire project defined using a controlled vocabulary is that it enables the use of regular expression commands to simplify data modelling, reporting, and communication pipelines. Regressions and sensitivity analyses can be done more succinctly, and constructing tables and figures requires less hardcoded variable definitions.\nAn additional advantage of using a controlled vocabulary is it can help automate the production of a project data dictionary. Using a defined procedure to name the variables in a project means that it is more straightforward to break apart these variable names and generate expanded explanations of each variable automatically to document and communicate the variables used in the analysis.\n\n\n\n\n\n\nRefactor or Preserve? Challenging the ‘If It Ain’t Broken, Don’t Fix It’ Mindset in Shiny App Lifecycle\nAs technology evolves, even well-crafted software eventually reaches obsolescence. This presentation explores the critical question: To refactor or not? Using the Pharmaverse/Teal framework as a case study, we examine the benefits and risks of transitioning a functional Shiny application to a modern framework.\nModern software frameworks often offer improved efficiency, enhanced stability, and expanded capabilities. However, they come with the tradeoff of upfront costs—such as learning new tools, adapting workflows, and ensuring long-term maintainability. The pragmatic adage, If it ain’t broken, don’t fix it, highlights the tension between maintaining stability and seizing opportunities for innovation. We will delve into a pragmatic assessment of refactoring decisions, weighing the advantages of adopting contemporary solutions against the potential challenges of disruption and technical debt. Attendees will gain insights into evaluating trade-offs, identifying critical factors for modernization, and applying lessons from the R/Pharmaverse Teal framework to make informed strategic decisions.\n\n\n\n\n\n\nBootstrap inference made easy: p-values and confidence intervals in one line of code\nBootstrap methods are a great way to get reliable p-values and confidence intervals, especially when classical model assumptions don’t quite hold or when analytical formulas aren’t available. Still, they’re not used as much as they could be—often because they seem complicated to implement.\nIn this talk, I’ll show how easy it can be. I’ll present the R package boot.pval, which lets you compute bootstrap p-values and confidence intervals for a wide range of models and parameters using just a single line of code. This includes tests of location, as well as regression coefficients in linear models, GLMs, survival models, and mixed models. I’ll also touch on how it works under the hood, how to extend it to custom test statistics, and how it can fit into your everyday analysis workflow.\n\n\n\n\n\n\nAdvanced Distance Metrics for High-Dimensional Clustering: introducing ‘distanceHD’ R-package\nThis presentation introduces the newly released R package, distanceHD, which provides distance metrics for high-dimensional clustering. We provide three distance metrics for measuring the separation between two clusters in high-dimensional spaces. The first metric is the centroid distance, which calculates the Euclidean distance between the centers of the two groups. The second is a ridge Mahalanobis distance, which incorporates a ridge correction constant, alpha, to ensure that the covariance matrix is invertible. The third metric is the maximal data piling distance, which computes the orthogonal distance between the affine spaces spanned by each class. These three distances are asymptotically interconnected and are applicable in tasks such as discrimination, clustering, and outlier detection in high-dimensional settings.\n\n\n\n\n\n\nAOUSDOHtools: An R Package for Social Determinants of Health Survey data in the All of Us Research Program\nAOUSDOHtools is an R package that was created to support standardized and reproducible scoring of the Social Determinants of Health (SDOH) constructs from survey data collected as part of the All of Us Research Program. Developed in conjunction with a user guide (Koleck et al., 2024, https://doi.org/10.1093/jamia/ocae214), the package provides functions to process raw SDOH Survey responses and compute 30 literature-informed construct-level scores across 14 SDOH constructs, such as Neighborhood Cohesion, Social Support, and Perceived Stress.\nThe package is designed for use within the All of Us Researcher Workbench, a secure cloud-based platform where the de-identified data are accessed and analyzed. The package is compatible with both Jupyter and RStudio environments hosted on the platform. AOUSDOHtools automates the data cleaning, recoding, scoring, and variable construction, which enables researchers to generate interpretable SDOH scores for downstream analysis.\nThe package is openly developed and maintained on GitHub and available through CRAN (https://cran.r-project.org/package=AOUSDOHtools) and GitHub (github.com/zhd52/AOUSDOHtools). It is intended to facilitate equitable and scalable research by making complex SDOH survey data accessible and analysis-ready for approved researchers working within the All of Us ecosystem.\n\n\n\n\n\n\nR You Compliant? Validating Packages for Regulatory Readiness\nAs R continues to gain momentum in clinical research, regulatory agencies are paying closer attention to how it’s used in regulated environments. Whether supporting statistical analysis, data visualization, or automation pipelines, R packages must meet stringent validation requirements to be considered fit for use in clinical trials and other regulated activities. But what does validation actually mean in this context—and how can researchers, data scientists, and system administrators ensure their R-based tools hold up under scrutiny? This talk will walk through practical strategies for validating R packages in alignment with regulatory expectations, including those from FDA, EMA, and under ICH guidelines such as E6(R3), E9, and M10. We’ll explore the intersection of open-source software and GxP compliance, unpacking the nuances of how to assess, document, and justify the use of community-developed or custom-built R packages. Attendees will learn: • What regulators expect when R is used in a clinical or GxP-regulated environment. • How to categorize R packages based on risk and intended use. • Validation approaches for both CRAN packages and internally developed tools. • How to document package selection, qualification, and performance testing. • Best practices for ongoing change control, version tracking, and reproducibility. • Real-world examples of validation frameworks and testing workflows using tools like {testthat}, {renv}, and {devtools}. Whether you’re part of a small academic research team or a large sponsor organization, this session offers practical guidance for creating defensible validation packages that support transparency, reproducibility, and regulatory compliance. We’ll also touch on tools and templates that can help streamline validation documentation and collaborate with Quality Assurance teams more effectively. By the end of this talk, you’ll walk away with a clearer understanding of what it takes to “make R compliant,” how to integrate validation into your development workflows, and how to future-proof your R environment in a regulated research setting. Because in clinical research, compliance isn’t just a checkbox—it’s part of building trust in our data, our methods, and ultimately, the science we support.\n\n\n\n\n\n\nFirst Steps with SQL in R: Making Data Talk\nCurious about SQL but not ready to dive into full-blown databases or external connections? This hands-on, beginner-friendly workshop is the perfect starting point. Using the lightweight and intuitive {sqldf} package in R, you’ll learn how to write SQL queries directly on your existing R data frames—no database setup required.\nSQL (Structured Query Language) is a powerful tool for querying and transforming structured data, and it’s widely used in clinical research, data science, and industry analytics. In this 3-hour introductory session, we’ll bridge the gap between R and SQL in the most approachable way possible—by working with the data frames you already use in R.\nWe’ll cover:\nWhat SQL is and why it’s useful alongside R\nThe basics of SQL syntax: SELECT, FROM, WHERE, ORDER BY, GROUP BY, and JOIN\nHow to use the {sqldf} package to run SQL queries on R data frames\nComparing SQL and dplyr for common data tasks\nWriting readable, reusable SQL queries inside R scripts\nThis session is geared toward R users with little to no SQL experience. You’ll learn through guided examples and live coding, with time to practice writing your own queries. There’s no need for databases or complicated setup—just bring your laptop with R and {sqldf} installed, and we’ll take it from there.\nBy the end of the workshop, you’ll be able to:\nWrite SQL queries to filter, sort, group, and join data frames\nUse {sqldf} to integrate SQL smoothly into your R scripts\nDecide when SQL might be more effective than tidyverse functions (and vice versa)\nGain confidence in querying data more efficiently—even with large or complex datasets\nThis workshop is especially helpful for analysts, students, and researchers who want to become more versatile in handling data but prefer to stay within the comfort of the R environment. It’s also a great stepping stone for those who may later work with external databases (e.g., REDCap, EDC systems, or clinical trial platforms).\nCome explore the power of SQL in a simple, approachable way—and learn to make your data talk.\n\n\n\n\n\n\nUnified Deep Learning Survival Analysis for Competing Risk Modeling with Functional Covariates and Missing Data Imputation\nDischarging patients from the intensive care unit (ICU) marks an important moment in their recovery—it’s a transition from acute care to a lower level of dependency. However, even after leaving the ICU, many patients still face serious risks for adverse outcomes, such as ICU readmission due to complications or subsequent in-hospital death. Such events can slow recovery, increase healthcare costs, and substantially impact patients’ quality of life. Accurate prediction of these outcomes could transform the way we care for ICU survivors. With improved predictive capabilities, clinicians can intervene sooner, personalize post-ICU support, and ultimately improve recovery while reducing the chances of returning to critical care. That said, making these predictions is anything but simple. ICU data is challenging—there are multiple competing risks (such as septic shock, ICU readmission, or death during or after hospitalization), and the data is both complex and multidimensional, spanning demographic factors, clinical information, and continuous waveform covariates (e.g., blood pressure and respiratory rate). Additionally, some data may be frequently missing, and time-dependent treatments make it even more difficult. Traditional competing risk models, such as cause-specific hazard models and the Fine & Gray sub-distribution hazard models, often fall short in managing these complexities. To address these challenges, our research team has developed an innovative deep-learning model specifically designed for competing risk analysis in ICU settings. This framework integrates discrete-time competing risk analysis techniques, adaptive data-driven basis layers with micro neural network for functional variables, and advanced Imputation-Regularized Optimization (IRO) method to manage missing data effectively. Unlike traditional basis representation methods—such as those using Fourier or spline bases—which do not leverage outcome information during dimension reduction, our approach fully integrates this information. This comprehensive approach greatly enhances our ability to understand and predict complex patient outcomes based on vital signs and other critical data. We validated our model through simulations and real-world ICU data from both a large public ICU database MIMIC-4 (over 12,000 patients) and the Cleveland Clinic’s ICU records (over 25,000 patients). Across different clinical scenarios, our deep-learning framework outperformed traditional methods on most occasions, showing better predictive accuracy based on the metrics, integrated brier score and concordance index. Ultimately, this research represents an important step forward in improving ICU patient care, enabling more precise, timely, and effective clinical decisions.\n\n\n\n\n\n\n{redquack}: An R Package for Memory Efficient REDCap-to-DuckDB Workflows\nHealthcare researchers working with REDCap often face challenges when using the API to read large clinical datasets. Random access memory (RAM) limitations of modern business and consumer hardware may not be capable of loading millions of records with hundreds of variables without pushing these systems to their limits.\nThis challenge became particularly evident at the School of Pharmacy, University of Pittsburgh, where data scientists manage a REDCap database containing clinical data from over 200 outpatient treatment centers. With 5 distinct forms resulting in nearly 3 million rows across 400 columns, traditional export methods using {REDCapR} failed due to memory constraints, while most analyses only required subsets of this data.\nThe {redquack} package was developed as a solution to this problem. It solves memory limitation through batch processing of REDCap data to DuckDB, an efficient columnar-storage database. This approach enables scientists and researchers to efficiently read large REDCap projects without memory constraints, process data in configurable batches of record IDs, optimize column types across batches, track extraction progress with detailed logging, and integrate with existing tidyverse workflows.\nUsing {redquack} is straightforward and requires minimal code. Researchers simply provide their REDCap API credentials and configuration preferences to the redcap_to_duckdb() function, which handles the extraction process. The resulting DuckDB connection can be immediately used with familiar dplyr syntax for filtering, grouping, and summarizing clinical data. This approach allows analysts to work with data too large to fit in memory while maintaining the workflows they may be accustomed to. The package also includes quality-of-life features like sound notifications (quacks on success) for long-running operations.\nThis presentation will showcase practical examples based on clinical research data from the School of Pharmacy at the University of Pittsburgh, demonstrating how {redquack} streamlines the data pipeline from REDCap to analysis. By eliminating memory constraints and simplifying the extraction process, {redquack} helps clinical researchers, data scientists and analysts, and research coordinators work more efficiently with large datasets while maintaining their existing workflows. The presentation will benefit anyone involved in clinical research who needs to process and analyze REDCap data in R, particularly those working with large multi-form projects or longitudinal studies where traditional extraction methods fail.\n\n\n\n\n\n\nValidating Shiny Apps in Regulated Environments\nShiny apps are increasingly used to deliver interactive tools in clinical and healthcare settings. But when these tools are used in regulated environments, validation becomes essential. How can we ensure that our Shiny apps are trustworthy, without stifling innovation?\nIn this talk we’ll explore practical approaches to validating Shiny applications in regulated contexts, drawing on principles from software engineering, quality assurance, and risk based validation. We’ll discuss key challenges like traceability, documentation, and versioning, as well as share techniques for building apps that are easier to validate from the start.\nI’ll highlight some of the tools and packages used in Jumping Rivers that can support validation workflows that satisfies both internal reviewers and external regulators, including the Litmusverse, a suite of R packages designed to assess code quality and generate validation evidence.\nBy the end of the session, you’ll understand: - Why validation is critical for Shiny apps in regulated contexts; - What elements make a Shiny app more or less validatable; - How to incorporate validation strategies into your development process.\nThis session is ideal for R users in pharma, clinical research, and healthcare who want to build confidence in their dashboards, while maintaining flexibility in how they work.\n\n\n\n\n\n\nEthical Considerations of Contrasts in Statistical Modeling of Medical Equity\nGiven that English is the dominant language for healthcare delivery in most places in the US, it can be argued that English is an appropriate referent language group for research design and statistical analysis. However, the decision to use English as the referent language centers English-speaking populations and perpetuates the narrative that English is the standard to which all other languages should be compared. Implicitly or explicitly, this assigns value to those who prefer to speak English. Such centering is not a practice isolated to language. Normalizing a group as the referent is often performed across other demographic and geographic variables in statistical modeling, including race, ethnicity, socioeconomic indicators, insurance status, sexuality, and rurality to name a few. Here, we discuss the use of contrasts in statistical modeling as a way to surface the impact of value judgements and their effect on inferential results, using R with an example from our institution.\n\n\n\n\n\n\nRHealth – A Deep Learning Toolkit for Healthcare Predictive Modeling\nDeep learning (DL) offers significant potential for advancing healthcare through improved analysis of electronic health records (EHRs), medical imaging, and physiological signals. However, the implementation of state-of-the-art DL models often requires advanced programming skills in Python, creating a barrier for clinical researchers and practitioners who primarily use R. Furthermore, applying complex DL methodologies is compounded by the inherent challenges in managing and processing the large-scale, complex, hierarchical, and multi-modal nature of healthcare data. While R is widely adopted in healthcare analytics, it currently lacks comprehensive, tailored toolkits designed for these specific data types and modeling complexities. This contrasts with the Python ecosystem, where toolkits like PyHealth have successfully standardized DL pipelines for healthcare, supporting diverse data, tasks, and models, and achieving widespread adoption (e.g., over 144k downloads and 11k stars).\nAs the main developer for PyHealth, we introduce RHealth, an open-source R package specifically designed to bring similar capabilities to the R community for healthcare predictive modeling using deep learning. Funded by the ISC grant from the R Consortium, RHealth aims to provide an accessible, integrated environment for R users. The initial development stage focuses on two core modules:\n\nEHR Database Module: This module provides a standardized framework to ingest, process, and manage diverse EHR datasets, including public sources (like MIMIC-III, MIMIC-IV and eICU datasets) and user-specific data formats (OMOP-CDM), ensuring data consistency for downstream modeling.\nEHR Code Mapping Module: This module facilitates the mapping between and within various medical coding systems (e.g., ICD, NDC, RxNorm), simplifying the integration of disparate clinical data sources.\n\nFuture funding will be sought to expand RHealth with additional modules, including a Healthcare DL Core module incorporating traditional machine learning and state-of-the-art healthcare-specific DL models (e.g., RETAIN, Transformers), and a Prediction module for various clinical prediction tasks (e.g., mortality prediction, readmission risk). Planned enhancements also include support for multi-modal data integration, clinical trial applications and large language model enhancement.\nRHealth seeks to empower the R-focused healthcare community by providing user-friendly tools, validated models, and reproducible benchmarks for leveraging advanced deep learning techniques. By lowering the technical barrier and building on established success in the Python domain, we aim to facilitate innovative clinical research and ultimately contribute to improved healthcare outcomes.\n\n\n\n\n\n\nOptimizing Public Healthcare Cost Recovery with R: A Use Case from Argentina\nThis work aims to demonstrate how the implementation of an open-source tool like R can optimize key processes in cost recovery within the public healthcare system, with a direct impact on its efficiency and sustainability.\nIn Argentina, the healthcare system is organized into three subsystems: the public, social security, and private sectors. In order to reduce health disparities, programs such as SUMAR have been developed. SUMAR seeks to guarantee equitable and quality access to healthcare for the population with exclusive public coverage. Through external funding from non-governmental entities, healthcare providers within the network of the Government of the City of Buenos Aires (CABA) receive financial incentives each time a basic effective coverage (CEB) health service is provided.\nIn CABA, the widespread use of the Electronic Health Record system across all healthcare providers facilitates the identification and tracking of patients enrolled in the program, enabling longitudinal follow-up and documentation of CEB services delivered. For each individual and each healthcare encounter, the health center receives additional resources. Within this framework, this public policy makes it possible to transform healthcare services into concrete financial resources. At the Operational Management of Health Information and Statistics, we have a technical team that leverages open-source tools—particularly R—to apply text mining techniques that help identify diagnoses, services, patients, and care pathways relevant to the preparation of the documentation required to access financial incentives.\nOur presentation aims to share with the R Medicine community a real-world use case from Latin America that highlights the value of open and sustainable tools in subnational public settings, promoting their adoption where they are most needed. The decision to use free and open-source tools is a strategic one, based on their flexibility to adapt to different technical needs and their long-term sustainability within the public sector. This approach allows for the systematization and acceleration of documentation processes, with a tangible impact on increasing the efficiency and volume of cost recovery efforts under the SUMAR Program. Throughout the presentation, we intend to show how applying data science tools in real public healthcare settings can lead to innovative solutions. In particular, we seek to highlight R’s potential to automate administrative workflows, improve process traceability, and transform data into concrete actions with measurable impact.\n\n\n\n\n\n\nExamining Factors Associated with Depressive Severity Among Cancer Survivors: An Analysis of the National Health Interview Survey\nThis study explores the factors linked to heightened severity of depressive symptoms in individuals who have self-reported a cancer diagnosis, utilizing data from the National Health Interview Survey (NHIS). A cancer diagnosis often brings significant psychological distress, making it essential to understand the correlates of depression within this group to guide targeted interventions and enhance patient well-being. This analysis focuses on a subgroup of NHIS participants who reported a cancer diagnosis, investigating the connection between depressive symptoms, as assessed by the Patient Health Questionnaire-8 (PHQ-8), and various demographic characteristics (e.g., age, sex, race/ethnicity, education, poverty), healthcare utilization patterns (e.g., delayed visits, emergency room visits, overnight hospitalization), and other factors (e.g., living alone, anxiety symptoms).\nThe study utilizes a data-driven approach to explore the predictors of depressive symptom severity. By leveraging a nationally representative sample, we investigate the associations between depressive severity and various demographic, health care utilization, and other factors. Using various R packages for data processing and analysis, descriptive statistics and survey-based regression are employed to identify significant correlates of heightened depression symptoms. Interaction terms will be considered to determine whether the relationship between certain factors and depression differs across various subgroups (e.g., by age, race/ethnicity, or gender, if data permits).\nThis study highlights the importance of large-scale public health datasets in elucidating the psychosocial challenges faced by patients who report having cancer. It underscores the need to integrate mental health considerations into cancer care. The findings aim to guide clinical decision-making and direct the development of precision mental health interventions within oncology settings.\n\n\n\n\n\n\nkidney.epi R Package for Facilitating Research in Diabetes, Kidney, Heart, and Other Diseases\nChronic Kidney Disease (CKD) is a major global health challenge, affecting approximately 700 million people worldwide and contributing to 3.2 million deaths annually. Despite this substantial burden, CKD is often excluded from many health prevention programs, and not taken into account in many clinical trials and noncommunicable disease screening programs. This leads to a concerning disparity, with only 10-20% of individuals with CKD being aware of the existing disease. Early detection and management of CKD are critical to slowing its progression to end-stage renal disease, a costly and debilitating outcome, and to prevent other complications. Fortunately, CKD can be easily diagnosed through two inexpensive and widely available tests: urine analysis and serum creatinine (and/or cystatine C) measurement with subsequent calculation of estimated glomerular filtration rate (eGFR). These two simple tests should be regularly performed in high-risk patients including those with diabetes, hypertension, and other CKD risk factors.\nDespite the simplicity and cost-effectiveness of these diagnostic measures, the integration of CKD testing into clinical practice and epidemiological studies remains limited. To bridge this gap, the kidney.epi R package has been developed by Scientific-Tools.Org. The package facilitates the exploration and analysis of CKD in diverse populations by providing a comprehensive set of functions tailored for kidney-related data analysis. The kidney.epi package enables researchers and data scientists to calculate eGFR using multiple validated equations, categorize results of urine analysis (albuminuria, proteinuria), and assign categories of complications risk based on the actual KDIGO classification. It allows to calculate eGFR based on the widely used CKD-EPI equation and more than 15 other equations based on both serum creatinine and/or cystatine C (both for children and adults). The package also has functions focused on kidney transplantation that allow calculating the Kidney Donor Profile Index (KDPI) and the Kidney Donor Risk Index (KDRI).\nOne of the key advantages of the kidney.epi package is the user-friendly design of functions that provide flexible label handling. Researchers do not need to modify datasets, recalculate different measurement units for laboratory values, or reformat existing labels for variables like sex or ethnicity. Instead, the functions accept user-defined labels and appropriate measurements units, thereby adapting seamlessly to various datasets.\nThe kidney.epi package allows automating kidney-related calculations in screening programs, clinical trials, and observational studies. It improves the accessibility and reproducibility of CKD-related research, and also contributes to the global effort to raise awareness, improve early detection, and ultimately reduce the CKD burden.\n\n\n\n\n\n\nMix, Pour, Share: The rUM Cocktail for Biomedical Project Packaging\nThe reproducibility crisis in biomedical research demands systematic approaches to documentation, data sharing, and analysis transparency. While R Markdown and Quarto have revolutionized reproducible reporting, challenges remain in organizing complete research projects with associated datasets, documentation, and presentation materials. We present rUM (version 2.2 rUM runner), an R package developed at the University of Miami to streamline the creation of comprehensive, CRAN-ready research packages with minimal coding effort. rUM enables researchers to bundle entire biomedical research projects—including analyses, datasets, documentation, and presentations—into a single distributable package using one-line function calls.\nKey features of rUM include:\n\nCreation of CRAN-ready package structures with a single function call\nAutomated templates for R Markdown and Quarto manuscripts as package vignettes\nEnhanced tools for documenting datasets with comprehensive metadata\nFunctions to create and integrate Quarto RevealJS presentations within packages\nTools to display and share slide decks stored within packages\n\nOur presentation will demonstrate how rUM addresses reproducibility challenges through a complete workflow: analyzing a pharmacokinetic dataset (medicaldata::theophylline), documenting the dataset with enhanced metadata, creating presentation slides with analysis visualizations, and bundling everything into a distributable package. rUM significantly reduces the technical barriers to creating R packages, making reproducible research practices more accessible to biomedical researchers who have even minimal of programming experience. By transforming completed projects into packages, researchers can ensure their work is discoverable, reusable, and properly documented—addressing critical elements of the reproducibility crisis in medical research.\n\n\n\n\n\n\nUnlocking Statistical Consistency Across Platforms: The CAMIS Project\nAs we transition to a world of multilingual programming, replication across software is critical. Comparing Analysis Method Implementations in Software (CAMIS) is an open-source repository dedicated to documenting the differences in statistical methodologies across a variety of software platforms such as SAS, R, Python, StatXact, and EAST. In the rigorously regulated medical research industry, ensuring the accuracy of results requires double or even triple programming, demanding matches in results from disparate systems.\nWe’ll introduce the PHUSE CAMIS project, which delves into the nuances between different software implementations of methods. All relevant code, case studies, results, and findings are stored in our GitHub repository (https://psiaims.github.io/CAMIS/).\nThrough practical examples, we highlight observed discrepancies and pitfalls and how CAMIS helps to bridge a user’s understanding across software. Beyond asking whether results match, we’ll emphasize the importance of assessing the robustness of the software packages and libraries generating these results.\nParticipants will gain valuable tools for efficiently investigating software discrepancies faced in daily tasks. We will address concerns and reassure current and future R users that, in most cases, results can be replicated across platforms. For those instances where replication fails, the CAMIS repository offers clear explanations to guide your understanding and resolution.\n\n\n\n\n\n\nDengue Forecasting Addressing the Interrupted Effect from COVID-19 Cases\nDengue is one of the deadliest vector-borne diseases in the world. Accurate time series forecasting of dengue cases is essential for preparedness—such as effective resource allocation for smoking to destroy breeding sites, distribution of medical supplies, and the development of early warning systems. In this study, we used weekly, district-wise dengue cases from 2007 to 2025 in Sri Lanka. Due to similar symptoms between dengue and COVID-19, case reporting from 2020 to 2022 may be unreliable, introducing an interrupted effect into the time series. This study investigates three modeling strategies to address this interruption. They are (i) excluding the interrupted period from model training, (ii) forecasting the interrupted period first and then using it for modeling, and (iii) down-weighting observations in the interrupted period. Data from 2007 to 2024 were used for model fitting, and data for 2025 were used for model testing. We evaluated the performance of these methods across 25 districts in Sri Lanka. There is no single method outperformed across all districts. The study further explores why certain approaches perform better in some districts than others, providing insights into tailoring forecasting methods to specific regional characteristics.\n\n\n\n\n\n\nThe power of {targets} package for reproducible data science\nReproducibility is a cornerstone of credible and robust data science. This talk delves into the powerful targets package showcasing how it streamlines and enhances reproducibility in data science workflows. The targets package in R provides a comprehensive framework for pipeline management, enabling eﬃcient dependency tracking, automated pipeline execution, and clear documentation of the entire data analysis process. It ensures execution of complex pipelines in consistent and isolated environments.\nCombined with tools like {renv} and docker, this approach eliminates the it works on my machine problem. Through real-world examples, attendees will learn how to leverage these tools to create reproducible, scalable, and maintainable data science projects, ensuring that their analyses can be reliably replicated and shared across diverse computational environments.\nThis workshop is designed for data scientists and analysts who are looking to enhance their ability to manage and scale up their analytical pipelines. By the end of the session, attendees will have a deeper understanding of the targets package, it’s capabilities and how to apply this package to their workflows, from exploration, to model building, to plotting and report generation.\n\n\n\n\n\n\nNo More Copy-Paste: Automating Patient Inquiry Tracking in Pharma with Shiny\nManaging patient support and prescription workflows often involves disparate tools, manual data wrangling, and time-consuming reporting. To streamline this process and provide real-time, actionable insights to field teams and DFAs (Dedicated Field Agents), we developed an R Shiny application that integrates prescription fulfillment data with Smartsheet-tracked patient inquiries.\nThis application serves as a dynamic operational hub, merging daily Excel-based prescription data with live Smartsheet API feeds to create a unified, interactive dashboard. Users can filter, sort, and export patient records while tracking key support metrics such as shipment history, days’ supply remaining, and open ticket status.\nThis solution has replaced previously manual workflows with a self-serve analytics tool that is intuitive, lightweight, and built entirely in R. It demonstrates how combining existing tools like Smartsheet and Excel with R Shiny can unlock powerful efficiencies for medical field operations without requiring heavy infrastructure or vendor solutions.\n\n\n\n\n\n\nSupercharging Statistical Analysis with ARDs and the {cards} R Package\nThe Analysis Results Data (ARD) Model is an approach that facilitates encoding statistical analysis summaries in a machine-readable format. This method seeks to streamline automation, improve reproducibility, encourage reusability, and enhance traceability in statistical practices. This talk will introduce the {cards} R package—a collaborative development by Roche, GSK, Novartis, Pfizer, and Eli Lilly within the Pharmaverse initiative. This powerful tool enables users to create ARDs, covering a range from straightforward statistical summaries like means and tabulations to complex analyses involving regression models and statistical tests.\nAttendees will discover the extensive capabilities of {cards} and how it can be paired effectively with tabling packages such as {gtsummary} and {tfrmt} to create insightful displays. By the end of the session, participants will gain a practical understanding of these tools and acquire actionable strategies for integrating them into their workflows, thereby enhancing the efficiency and reliability of their statistical analyses.\n\n\n\n\n\n\nAn Accelerometry Biomarker Framework with Application in Vigilance in UK Biobank Data\nThis talk introduces a framework for assessing vigilance using accelerometry data from the UK Biobank. We define vigilant and non-vigilant participant groups based on self-reported questionnaires, resulting in 95 matched pairs after propensity score matching on physical and behavioral characteristics. We present the sorted spectral image, a structured representation of daily accelerometry data derived from 5-minute bouts processed via Discrete Fourier Transform. A simplified convolutional neural network, inspired by AlexNet, is developed to classify participants based on these spectral images. Using 20-fold cross-validation, the model achieves an out-of-sample F1 score of 0.576 and an AUC of 0.539 at the sample level for participants aged 65 or younger. Subject-level analysis of this younger cohort yields an F1 score of 0.539 and an AUC of 0.564. These findings demonstrate the potential of accelerometry-derived biomarkers for non-invasively assessing vigilance, opening avenues for broader applications in monitoring cognitive states and movement-related disorders.\n\n\n\n\n\n\nPreprocessing Electronic Health Records for Analysis-Ready Data in an Asthma Cohort\nElectronic health record (EHR) data has become an invaluable resource of extensive patient data for large-scale studies. However, EHR data is often accompanied by inconsistent data entries and formats which can involve a lengthy process of understanding the data and data preparation. Here, I will discuss several specific challenges observed when preparing EHR data for analysis using the tidyverse suite in R. Drawing on examples from an asthma cohort study, I will demonstrate how to clean and transform demographic characteristics, diagnostic codes, medications, and laboratory results data at both an encounter and patient level using packages such as dplyr, tidyr, stringr, and lubridate. This lightning talk will provide insight on common EHR data quality issues and provide strategies for resolving them to prepare users for their own research.\n\n\n\n\n\n\nSwimmer Plots with ggswim\nTitle: Simplifying Swimmer Plots in R using ggswim\nMotivation\nSwimmer plots are a valuable tool for visualizing treatment timelines, such as those in clinical trials. They provide a clear, interpretable way to track subjects over time, capturing various discrete events in a compact and accessible format offering a high-level comparative view of a population. Despite their usefulness, swimmer plots are not trivial to generate in R, limiting their use across research teams.\nCreating swimmer plots using ggplot2 in R can be technically demanding. Proper scale alignment and legend composition requires deeper familiarity with ggplot2 internals than one might typically expect from a researcher. While some packages exist that support swimmer plot development, we were not able to find any that bridge the gap of easing plot generation while maintaining full compatibility with the grammar of graphics.\nApproach\nThe ggswim package was developed as an extension to ggplot2 to address these challenges. It introduces a streamlined grammar specifically for swimmer plots, organizing visual elements into two conceptual categories: lanes and markers. Lanes represent continuous duration such as time on a given study while markers represent discrete points such as adverse events or outcomes. This framework integrates smoothly with existing tools that follow the grammar of graphics, allowing users to layer and label plot components using concise and intuitive syntax that maintains full compatibility with ggplot2.\nConclusion\nggswim fills a key gap in the R visualization toolkit by making swimmer plots accessible to a broader audience without sacrificing flexibility or aesthetics. By reducing the technical overhead typically required to produce swimmer plots, ggswim promotes reproducibility, transparency, and more effective collaboration in medical research settings. In this talk we’ll focus on not only the technical achievements of ggswim, but also the many changes it went through to get to its current state and what prompted its development in the first place.\n\n\n\n\n\n\nVisualising data for patients: create accessible charts\nVisualising data for patients or other stakeholders may be difficult. Most of the time, our audience does not have a scientific or medical background, so our duty is to present data in a way that is understandable for them. To create clear and accessible charts, there are several factors to consider, such as decluttering, accessibility of the colour palette, and fonts.\nDuring this demo, we will see how to create accessible and clear charts in R. Attendees will learn how to create a new palette in R that is colourblind-friendly, and also how to create an autism-friendly palette. We will check if the colours in the chart are colourblind friendly in R using colourblind, and we will see how a brand palette can be made accessible. Starting with a brand palette that is not colourblind-friendly, we will create a new one that is colourblind-friendly. Moreover, we will look for fonts that have high readability and see how to include them in our R code.\n\n\n\n\n\n\nUsing R shiny to perform and automate decision-analytic modeling for cost-effectiveness analysis\nR is increasingly used for decision-analytic modeling such as Markov and microsimulation modeling in recent years for economic evaluation (cost-effectiveness, cost-utility, budget impact), thanks to the development of guidelines and packages. Base R, however, is still the most flexible way of constructing these models, which can then be rolled up into Shiny applications. In this presentation, I will demonstrate two cases of using base R and R Shiny for cost-effectiveness analyses: 1) a specific use case of Markov modeling for cost-effectiveness of remote patient monitoring, which was developed for better presentation of the results, and 2) a generic set-up which can be quickly adapted for several Markov model-based cost-effectiveness analyses. The generic set-up will include importing model input parameters from csv/excel files for various models with different model structure and number of parameters, which the script will automatically handle. I will show how we can either run the model inside the Shiny app itself or, in case of models that takes several hours to days to run, we can run and save the model results outside of Shiny and use Shiny to summarize the results in tables and figures.\n\n\n\n\n\n\nIn the Nix of Time: Creating a reproducible analytical environment with Nix and {rix}\nThe world of data science in medical research has seen tremendous growth in large part to the innovations powered by open-source software, especially in the ecosystem surrounding R. Even with the advanced tooling available to perform cutting-edge analytics and create novel software such as R packages, developers will encounter unique challenges to ensure reproducibility from both the analytical side as well as the development environments used to create software. A perfectly valid combination to address these challenges is using {renv} to manage R package dependencies and Docker/Podman to handle system-level dependencies. In recent years, the Nix package manager has emerged as an appealing framework to manage the full dependency stack of software projects, albeit with a rather steep learning curve. In this hands-on demonstration, I’ll share how the new {rix} package (authored by Bruno Rodriguez and Philipp Baumann) has turbo-boosted my R package and reproducible analysis workflows, empowering me to rapidly iterate on new ideas while ensuring reproducibility across a wide variety of projects.\n\n\n\n\n\n\nApplication of attention mechanism to improve performance of surveyed llm/mllm used across R/Medicine\nPrivate-public partnerships have been engaged with regulatory agencies to foster adoption and conformance to mandated submission guidelines. The Linux Foundation / R Consortium Pilot Series with FDA have focused considerable efforts in collaboration with industry sponsors to provide proof of concept studies to accelerate conformance to technical guidelines required in modern technical submissions. The industry teams engaged in these pilot studies have recently directed focus into areas where use of llm/mllm might assist in areas ranging from use of Gen[Ai] to produce instructive vignettes to describe analytical datasets to auto-generation of the Analysis Data Reviewer’s Guide (ADRG) to be included for Agency Reviewers as part of the eCTD (Electronic Common Technical Document) submission.\nThe hope for this demonstration is to allow the audience to engage with and understand the motivation of the model architectures including how the {attention} mechanism improves output performance, for example, with vignettes describing safety and efficacy data sets used in the R Consortium Pilot Series with FDA. My hope is to further raise awareness and participation about the importance of these Pilot Series in R (and historically in context of the almost two decades efforts ongoing with the Standards and Regulatory Agencies) not only to drive adoption but also push the industry forwards in alignment and implementation to meet the mandated changes. Excellent progress has been made and the hope is to continue the acceleration to include everyone who wishes to participate even if only through organizational efforts at the local level using the public repository provided with the demonstration to raise the R/Medicine Ecosystem with a working examples of clinical importance for analytics and with regulatory submissions.\nThe Demonstration Agenda (1 hour) 00:00-00:10 - Introduction: History and Technical Context - Motivation 00:10-00:25 - Background of Transformer Architecture with {attention} used in R/Medicine 00:25-00:50 - Demo of {attention} mechanism for vignette generation of Analysis Dataset Descriptions 00:50-00:59 - Q&A, Concluding Remarks\nMost importantly, every effort is afforded to expand inclusion so every person feels welcome and encouraged to participate with the demonstration provided through the event.\n\n\n\n\n\n\nREDCapSync and RosyREDCap: two development R packages using the REDCap API for standardized data pipelines and exploratory data analysis\nR and REDCap are both widely utilized in medicine, including basic science, clinical research, and clinal trials. Both have independent strengths, but together they can create powerful data pipelines. Several R packages exist for using the REDCap Application Program Interface (API) such as, REDCapR, redcapAPI, and tidyREDCap. However, there are no standard R packages for maintaining synchronized data pipelines from REDCap or comprehensive shiny applications that are built to work for any possible REDCap project.\nREDCapSync streamlines comprehensive metadata and data extraction from one or multiple REDCap projects with a handful of functions like setup_project and sync_project. Using a cache of the last project save, a file directory, and the REDCap log, REDCapSync only updates the data that has been changed since the last API call. Each project is maintained as a standardized R list object that can be used downstream for the best that R has to offer in statistics, visualization, shiny apps, and more! Experimental functions exist for saving adding derived variables, merging REDCap forms, and generating data subsets that also refresh with sync_project. Furthermore, REDCapSync can be used to upload labelled data with the API, a feature not available on the REDCap website.\nRosyREDCap is an R shiny application that launches a local website for exploratory data analysis of REDCap projects. It is built to load all previous projects that were setup with the REDCapSync package. The user is able to toggle between projects, deidentify data, perform ad-hoc data visualizations, and more.\nUsing tools like REDCapSync and RosyREDCap allow even new R users to harness the power of the REDCap API without the burden of having to learn the details. Simply get approved access to REDCap API token, choose a safe file directory, sync your project, and explore! At R medicine, I plan to demonstrate several examples and use cases for REDCapSync and RosyREDCap R packages to demonstrate how the combined strengths of R and REDCap are perfect for maintaining strong reproducible clinical data pipelines that improve research and patient care.\n\n\n\n\n\n\nBiomarker Identification by Means of Frequent Itemset Mining and Contrast Set Mining\nWe demonstrate the utility of using both frequent itemset mining and contrast set mining to analyze single-cell RNA-seq (scRNAseq) data. Whereas machine learning approaches to scRNAseq data analysis identify ensembles of salient genes that may or may not be somehow connected, itemset mining identifies groups of genes whose over- or under-expression necessarily co-occur. These co-occurrences may present evidence for pathways associated with particular endpoints. The workflow includes four major steps: (1) data retrieval and curation, (2) feature (gene) selection, (3) data discretization, and (4) itemset mining. Results from a clear cell Renal Cell Carcinoma (ccRCC) study is used for this demonstration. Patients in this study were diagnosed with both early-stage and late-stage ccRCC. We present results showing the success of frequent itemset mining and contrast set mining in identifying biomarkers (sets of genes) that differentiate early-stage ccRCC patients from late-stage ccRCC patients.\n\n\n\n\n\n\nCo-occurrence analysis and knowledge graphs for suicide risk prediction\nMental health disorders are complex phenotypes and current diagnoses would benefit from introducing multidimensional assessments and taking into account the spectrum and gradients of disorders observed. To these ends the advent of novel natural language processing (NLP) methods present new opportunities for leveraging unstructured text data as clinicians notes in electronic health records, which detail why a diagnosis was made and why specific medications were prescribed.\nThe CELEHS laboratory at Harvard Medical School is part of the Center for Suicide Research and Prevention project led by Massachusetts General Hospital (MGH) and aims at developing tools for clinicians to measure the suicide risk of patients. In previous publications, collaborators have highlighted the importance of using NLP to address the limitations of the International Classification of Diseases in accurately identifying cases of suicide attempts, which lead to consistently under estimating their true prevalence in statistical analyses.\nAs the CELEHS laboratory, our contribution to this project focuses on two main goals: first, developing robust survival models on codified data that can be transferred between institutions as MGH and Cambridge Health Alliance; second, leveraging name-entity recognition, co-occurrence analysis, knowledge graphs, and large language models to further extract insights from clinicians notes. In both institutions, we analyze cohorts of approximately 5,000 teenage patients admitted in psychiatric departments.\nIn this talk I will present and introduce the open-source tools we developed to perform these analyses, as the kgraph and nlpembeds R packages, both of which are available on CRAN. The methods underlying these packages were introduced last year in my previous talk at R in Medicine 2024 “Word embeddings in mental health” and enable to efficiently analyze large amounts of electronic health records data, both codified and unstructured.\nOur latest developments reveal how NLP enables to better interpret predictive features that would seem clinically irrelevant by considering only their use in the codified data, but which are actually key factors of why specific diagnoses were performed by clinicians.\n\n\n\n\n\n\nOperational Risk Assessment of R Packages: A Configurable Framework for Pharmaceutical Adoption\nThis talk introduces a novel framework addressing one of the most significant barriers to open-source adoption in the pharmaceutical industry: the risk assessment of R packages. We present a nuanced approach that positions risk appetite as the foundational element for developing effective assessment strategies across the spectrum of organisational tolerance levels. Our framework recognises that risk appetite varies significantly between organisations—from those accepting minimal risk to those embracing calculated opportunities. This variation directly impacts assessment requirements: organisations with higher risk tolerance may implement streamlined evaluations focused on basic suitability and compatibility, while risk-averse entities typically demand rigorous validation protocols before production deployment. To operationalise this framework, we introduce two complementary R packages: {litmus} and {litmus.score}. Building upon the R Validation Hub’s pioneering work, these tools enable organisations to implement tailored scoring systems that reflect their specific risk profiles. The packages generate both comprehensive quality scores and granular category assessments across dimensions including code quality, documentation, community adoption, and maintenance patterns. The system’s strength lies in its configurability, evaluating measurable package attributes—such as test coverage metrics, documentation completeness, and maintainer diversity—to produce meaningful quality indicators that align with organisational risk thresholds. This presentation will demonstrate how pharmaceutical organisations can leverage this framework to make informed, risk-appropriate decisions about R package adoption."
  },
  {
    "objectID": "speaker_info.html",
    "href": "speaker_info.html",
    "title": "Speaker guide",
    "section": "",
    "text": "This page is intended for folks who have had their abstract accepted for a lightning talk or regular talk at R/Medicine. Congratulations! We are excited to welcome you as a presenter.\nPlease click through the tabs on this page to access information."
  },
  {
    "objectID": "speaker_info.html#welcome",
    "href": "speaker_info.html#welcome",
    "title": "Speaker guide",
    "section": "",
    "text": "This page is intended for folks who have had their abstract accepted for a lightning talk or regular talk at R/Medicine. Congratulations! We are excited to welcome you as a presenter.\nPlease click through the tabs on this page to access information."
  },
  {
    "objectID": "speaker_info.html#schedule-and-timing",
    "href": "speaker_info.html#schedule-and-timing",
    "title": "Speaker guide",
    "section": "Schedule and Timing",
    "text": "Schedule and Timing\nThe schedule has been posted on the R/Medicine web site.\nAll program times are in eastern time\n\nAll lightning talks are ten (10) minutes in total (including Q&A).\nAll regular talks are twenty (20) minutes in total (including Q&A).\n\nPlease ensure your pre-recorded talk does not go over the allotted time"
  },
  {
    "objectID": "speaker_info.html#platform-specifications",
    "href": "speaker_info.html#platform-specifications",
    "title": "Speaker guide",
    "section": "Platform & Specifications",
    "text": "Platform & Specifications\nWe will be using the virtual platform Zoom Events that will allow pre-recorded talks to play while speakers join the chat live (and drop links into the chat) for Q&A during the session."
  },
  {
    "objectID": "speaker_info.html#pre-recording-information-tools",
    "href": "speaker_info.html#pre-recording-information-tools",
    "title": "Speaker guide",
    "section": "Pre-recording Information & Tools",
    "text": "Pre-recording Information & Tools\nAll regular talk and lightning talk speakers must pre-record their talk, which will be played through the event platform.\nSome suggested tools to use for recording are Quicktime, Zoom, a screen recorder, or something similar. The recording should show your slides or screen and optionally yourself, using a picture in picture style format. Please share the actual video file, in MP4 format, not a link to a streaming service such as YouTube or Vimeo. The file should be named as “WeekdayOfTalk-Firstname-Lastname.mp4”, for example “Thursday-Jane-Doe.mp4” for a talk by Jane Doe that will take place on Thursday. Upload your recording here by midnight EDT on Monday, June 2nd.\nPlease feel free to reach out with any questions."
  },
  {
    "objectID": "speaker_info.html#prepare-your-slides",
    "href": "speaker_info.html#prepare-your-slides",
    "title": "Speaker guide",
    "section": "Prepare Your Slides",
    "text": "Prepare Your Slides\n\nRemember that people can either listen to you speak or read your slides, they can not do both at once.\nKeep your slides visually minimal\n\nYour slides should support your message, not distract from what you are saying.\n\nUse color to highlight key points and/or key words.\nSet your base font size to be somewhat large (16 or 18 point).\nAvoid showing Blue on Black.\nUse high contrast colors between your slide background and text contrastchecker\nMake sure all your slides are color blind safe. Take a screenshot and paste the image here: color-blindness-simulator. Be sure to check all the different forms of color vision weakness including Monochromacy/Achromatopsia.\n\n\nConfigure your CodeEditor/IDE\n\nSet the font on your code editor to be large enough that you can read the text from a few feet away.\nIf you use the RStudio or Positron IDE you can make everything larger with cmd + on Mac or ctrl + on Windows.\nIf you work on a large display, take a screen shot showing your code and view it on a 13 inch laptop or tablet.\n\n\n\nShowing Code In Your IDE\n\nRemember that most IDEs can collapse code blocks.\n\nConsider hiding material that you have not talked about yet.\nIf a code block does setup, show it and collapse it.\n\n\n\n\nShowing Code In Slides\n\nConsider highlighting key points as you are taking about them.\nIf you are working in Quarto you can fold/show your code using code chunk options like this:\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n\n# code to show goes here\n```\n\nShowing code with line numbers makes it easier for people to ask questions.\nIf you are making slide with Quarto you can draw attention to lines of code with a couple of techniques. Consider these options:\n\nCode Annotation\nCode line highlighting\n\n\n\n\nSlide templates\nR/Medicine slide templates are available for:\n\nPowerpoint. Download the template here.\nQuarto. See details below.\n\n\nCreating RMed Slides in Quarto\nTo prepare your RevealJS presentation for R/Medicine using our prebuilt template, follow this outline.\n\nInstall the {rUM} package from CRAN:\n\nremotes::install_cran(\"rUM\")\n\nInitialize a new slide project that includes the RMed templates. Be sure to include template = \"rmed\". A slides directory will be created in your current path as defined by here::here() unless you use the path = argument. This demonstration will create the directory evaluated by here::here():\n\nFor example, this code will make a slides folder on your Desktop:\nrUM::write_slides(\n  \"bestest_talk_ever\", \n  path = \"~/Desktop\", \n  new_folder = \"the_bestest_talk\", \n  example = TRUE, \n  template = \"rmed\"\n)\n\nThe slides directory will include:\n\n\n&lt;project&gt;.qmd\nslides.scss for presentation styling\nrstudio_default-light.theme that will render your code examples (i.e., syntax highlighting) as displayed in RStudio’s light theme\nimg directory containing template background, hex logo, and .ico file to add styling to your browser’s tab once the presentation is rendered.\n\nNOTE: clean_title_page.html includes JavaScript that modifies elements on the title page only. We recommend against modifying this file.\n\n\n\nRender the document using either the RStudio “Knit” or Positron “Preview” GUI buttons, Ctrl+Shift+K (CMD+Shift+K for macOS), or use the terminal command:\n\nquarto preview slides/&lt;project&gt;.qmd --no-browser\nWe recommend you modify the following values in the presentation YAML:\n\nTitle, subtitle, & author details\nfooter: complete the URL to the project repository for a working HTML hyperlink\n\nAlter the text ([Slides are here]) for a more custom hyperlink at the slide bottom"
  },
  {
    "objectID": "speaker_info.html#technical-tips-for-virtual-presentations",
    "href": "speaker_info.html#technical-tips-for-virtual-presentations",
    "title": "Speaker guide",
    "section": "Technical Tips for Virtual Presentations",
    "text": "Technical Tips for Virtual Presentations\n\nAudio – as counterintuitive as it may sound, the single most important factor in a good video, is the audio quality.\nEliminate ambient noise – close the doors and windows. You’d be surprised how much environmental noise gets picked up.\nLighting – Do not put lights overhead and don’t put any lights or windows behind you as they will alter the light levels in your videos and create shadows.\nBackground – don’t be afraid to show your natural environment – bookcases, plants, paintings – as long as they are not too distracting.\nFraming – place yourself slightly off-center to the left or right rather than directly in the middle of the frame.\nCamera Height – the lens should either be directly level or pointing ever so slightly downwards towards your face.\nStand – we recommend you stand during your presentation to help project your voice and improve your posture. However, if you’re more comfortable sitting, then please do.\nTimer – Have a clock to keep track of the time you have remaining.\n\nFrom: https://www.greatspeech.co/video-presentations/"
  },
  {
    "objectID": "speaker_info.html#lighting-webcam-and-microphone-best-practices",
    "href": "speaker_info.html#lighting-webcam-and-microphone-best-practices",
    "title": "Speaker guide",
    "section": "Lighting, Webcam and Microphone Best Practices",
    "text": "Lighting, Webcam and Microphone Best Practices\n\nBest Practices for Lighting\n\nFor best results, use natural light and supplement with additional light as needed.\nKeep natural light in front of you to avoid shadows. A bright window behind you can make you appear as a dark silhouette.\nInterior rooms with no natural light source may require additional targeted lighting, such as a ring light, to brighten the speaker’s face.\n\n\n\nBest Practices for Webcams\n\nTo ensure the speaker is looking directly at the audience, place the webcam at eye level.\nAvoid distracting backgrounds by checking the surroundings behind you to make sure there are no distracting colors or movement.\nPresenters should use chairs that are adjustable for height but do not swivel. Swiveling on camera creates a poor attendee experience and can be distracting.\n\n\n\nBest Practices for Microphones\n\nUse external microphones whenever available, as microphones built into computers and cameras often have lower quality.\nAn external microphone allows the speaker to place it in the optimal location for sound.\nPlace the microphone close to the speaker’s mouth, but not in the camera view.\nTest audio levels in advance.\nManage noise by turning off fans, phones, or speakers and keep ambient noise to a minimum.\nDo not touch the microphone while unmuted\nSend your video to a friend prior to submission to check the sound and video quality\n\n\n\nDress Code\nThere is no dress code for presentations, and we encourage you to be comfortable. That said, you must be aware that the Code of Conduct applies to this space, both in terms of what you show on camera and what you say. We ask that you be tasteful and considerate in choosing your clothing and surroundings. Keep in mind that we are a global community. Please refrain from wearing shirts with global brand logos that are not your own. Solid colors (not white) also work best instead of prints."
  },
  {
    "objectID": "speaker_info.html#live-qa",
    "href": "speaker_info.html#live-qa",
    "title": "Speaker guide",
    "section": "Live Q&A",
    "text": "Live Q&A\nFor the main meeting on Thursday and Friday, it is required to have a presenter or co-presenter available for the live chat while the pre-recorded talk plays. This is one of the best features of R/Medicine, as the whole community gets to discuss the topic with the speaker during the talk without being rude. It is often helpful to prepare for the live chat by assembling a document with any links, references, etc. that you can copy and paste into the chat when appropriate. This includes links to slides or GitHub repos, as appropriate.\n\nLearn the Content: Familiarity with the content allows a speaker to focus on presenting, rather than trying to remember the points to make. To minimize worry about forgetting elements of the presentation, include notes in your presentation file and have a prepared e-document of your links, script, or talking points that you can paste into the chat.\nPractice Makes Perfect: Speakers should practice their content delivery in the environment in which they will deliver it, such as in front of a computer. Presenting alone to a computer can be awkward at first. To make speakers more comfortable, ask colleagues, roommates, or family to sit in front so they can present to familiar faces.\nUnderstand the Tools: Speakers should understand and utilize the content options available to them, to maximize the effectiveness of the presentation technology. It’s important to know the basic functions of the software, e.g. how to advance slides, manage Zoom Q&A or chats, before the presentation.\nSpeak Up: Check audio levels before presenting, but also make sure to breathe at regular intervals to speak audibly and clearly. Maintaining a clear, even tone throughout the presentation will allow the audience to hear it without adjusting their volume settings.\nLook at Your Camera: If presenting via video, remember, the webcam is your link to your audience. Make eye contact with the camera so it appears to the audience that you are speaking directly to them.\nDon’t Fear Mistakes: Humans make mistakes, even during presentations. Realize that flubs happen and they won’t derail your presentation – unless you let them. Just keep going in your planned presentation and remember, the audience is forgiving.\nBe Prepared: During the presentation, have a glass of water nearby to sip as needed. Also, keep handy a printout of your slides or notes in case you need to refer to them.\n\nFrom: https://www.inxpo.com/assets/pdfs/litepapers/How-To-Be-An-Engaging-Speaker.pdf"
  },
  {
    "objectID": "speaker_info.html#code-of-conduct",
    "href": "speaker_info.html#code-of-conduct",
    "title": "Speaker guide",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease read and abide by our Code of Conduct. We ask that speakers especially review this code of conduct and are inclusive in the words and images used during their presentation."
  },
  {
    "objectID": "speaker_info.html#links-to-additional-resources",
    "href": "speaker_info.html#links-to-additional-resources",
    "title": "Speaker guide",
    "section": "Links to additional resources",
    "text": "Links to additional resources\nBest Gear for Online Meetings – Webcams, lights, mics, tripods and more\n19 Video Presentation Tips to help you give a great presentation (even if you hate the way you look on camera)\n9 Tips for Giving Engaging Virtual Presentations – This article gives 9 tips and within each tip has folks from the tech world giving their advice in a fun/relatable way.\nPACE Acronym for Virtual Presentations\nChecklist for Speakers – this article provides checklists applicable for speakers that are live streaming.\nR-Ladies video tips\nYour Perfect Tech Talk\nA general MIT lecture on How to Speak"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 RMedicine_website authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "index.html#an-r-consortium-virtual-conference",
    "href": "index.html#an-r-consortium-virtual-conference",
    "title": "R/Medicine 2026",
    "section": "AN R CONSORTIUM VIRTUAL CONFERENCE",
    "text": "AN R CONSORTIUM VIRTUAL CONFERENCE"
  },
  {
    "objectID": "index.html#why-attend",
    "href": "index.html#why-attend",
    "title": "R/Medicine 2026",
    "section": "WHY ATTEND",
    "text": "WHY ATTEND\nThe R/Medicine conference provides a forum for sharing R based tools and approaches used to analyze and gain insights from health data. Conference workshops and demos provide a way to learn and develop your R skills, and to try out new R packages and tools. Conference talks share new packages, and successes in analyzing health, laboratory, and clinical data with R and Shiny, and an opportunity to interact with speakers in the chat during their pre-recorded talks."
  },
  {
    "objectID": "index.html#brought-to-you-by",
    "href": "index.html#brought-to-you-by",
    "title": "R/Medicine 2026",
    "section": "BROUGHT TO YOU BY",
    "text": "BROUGHT TO YOU BY"
  },
  {
    "objectID": "index.html#mailing-list",
    "href": "index.html#mailing-list",
    "title": "R/Medicine 2026",
    "section": "MAILING LIST",
    "text": "MAILING LIST\nJoin our mailing list to hear all the latest about events, news and more"
  },
  {
    "objectID": "index.html#help-edit-this-website",
    "href": "index.html#help-edit-this-website",
    "title": "R/Medicine 2026",
    "section": "HELP EDIT THIS WEBSITE",
    "text": "HELP EDIT THIS WEBSITE\nThis entire website was made using Quarto and R.\nIf you notice any problems or have any additions please submit a Pull Request to our public GitHub Repo"
  },
  {
    "objectID": "Events.html",
    "href": "Events.html",
    "title": "Past R/Medicine Conferences",
    "section": "",
    "text": "R/Medicine 2025\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2024\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2023\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2022\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2021\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2020\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2019\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n  \n\n  \n\n  \n    \n      \n    \n  \n  \n    \n    R/Medicine 2018\n    Event Website\n    YouTube Playlist\n  \n  \n  \n  \n  \n    \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Contact.html",
    "href": "Contact.html",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "All inquiries can be sent to rmedicine.conference@gmail.com."
  },
  {
    "objectID": "Contact.html#contact-the-rmedicine-team",
    "href": "Contact.html#contact-the-rmedicine-team",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "All inquiries can be sent to rmedicine.conference@gmail.com."
  },
  {
    "objectID": "Competition.html",
    "href": "Competition.html",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "University of Jos, Jos, Plateau State, Nigeria, Department of Community Medicine, MSc Field Epidemiology\n\n\n\n\nRSC Statistical Consulting, Statisticians\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe R/Medicine planning committee welcomes your participation in the virtual R/Medicine data challenge. Participants will have from now until Tuesday, May 20th, 2025 to work on submissions for the challenge. There will be 2 prizes: One $200 prize for the Student Division, and One $200 prize for the Professional Division, as well as a guaranteed spot for each division to present the findings at the 2025 R/Medicine conference. The quality of analyses/Quarto docs, as well as tables and visualizations will be considered.\nChanging attitudes towards vaccination in the US have significantly lowered childhood measles vaccination rates, as uptake of the recommended two doses of MMR vaccine before entering school has frequently fallen below the 95% recommended for community immunity.\n\n\n\nIn this data challenge, you will analyze MMR vaccination rates over time and by geographical area, as well as measles case rates and complications.\nWe ask that all analyses be done and submitted as Quarto documents. Participants can submit as an individual or as part of a team (but not both). The maximum team size is 3. Your goal will be to tell a data story about what is happening with measles immunity and outcomes in the US and the world in 2025.\nWe encourage you to use any and all of the public datasets available at: https://github.com/fbranda/measles. We encourage you to explore any of the csv files at the top level, as well as those in the measles/USA/data/ folder. Note that a lot of the contemporaneous files are updated each week, so be sure to use the latest data in your final submission.\nA special thank you to Francesco Branda, Adjunct professor of the Unit of Medical Statistics and Molecular Epidemiology at Campus Bio-Medico University of Rome, for creating and maintaining this valuable repository of measles data.\nAs this is an ongoing concern, datasets are being collected and updated in real time, ad we encourage you to document trends, use interactive formats like ggplotly and shiny-live, and to consider forecasting the future with tools like the {forecast} and {tidyverts} packages. One good reference for forecasting from Rob Hyndman can be found here.\nIn addition to the provided datasets on this Github site, you may request to use additional publicly available data in your submission by submitting a request (with the dataset) by April 29th, 2025 at 5:00PM ET. If approved, the dataset will be made available to all participants.\nYou will be evaluated by judges based on the relevance, completeness, and quality of your submission.\nJudges include:\nRaymond Balise, PhD, University of Miami\nPeter Higgins, MD, PhD, MSc, University of Michigan\nBryan P. Mayfield, PharmD, MS, Precision Analytical\n\n\n\nWhat is the growth rate of measles cases in the US vs Europe?\nAre there particular counties or states at risk due to low vaccination rates?\nHow are vaccination rates changing over time?\nWhat is your projection for the number of measles cases (and complications) in 2026?\n\n\n\n\n\nWhen: Now - May 20th, 2025 (submissions accepted through 11:59 PM ET)\nWhere: The R/Medicine data challenge is entirely virtual, with information and rules of the challenge available on this website. Updates will be posted on this website.\nWho you are: We welcome any participants over age 18, especially undergraduate students, graduate students, and early professional data scientists and biostatisticians. Analysts based in academic institutions, government statistical offices, think tanks, policy labs, and community organizations are encouraged to participate. Participants will be asked to submit to either the Student or Professional category, and we may request verification of eligibility for the student category.\nWhat topics you can explore: Participants can analyze the linked measles data sets in tandem with with any other related publicly available data submitted for approval before April 29th, 2025.\nSubmissions and evaluation: Participants will conduct their analyses and submit a short project narrative that describes the research question, analytic approach, and key findings. We encourage participants to find creative ways to incorporate tables, visualizations, and other aspects of data storytelling to create a compelling narrative. In addition to their completed analysis with the indicators they used, participants will be asked to submit documentation describing each step of their process. The documentation should be detailed enough as to make the project fully replicable. The narrative, methods, organization, and documentation of each participant’s project will be evaluated for relevance, completeness, and quality. More information on evaluation will be added to the FAQs section at the bottom of this page.\nNotification: Winners will be notified by Monday May 26th, and will be required to submit the pre-recorded talk on their findings by Monday June 2nd.\n\n\n\nSubmissions will be judged separately in the Student Division (any level of student, including graduate student) and Professional Division (any post-graduate level position). For each division, the prize will include a guaranteed regular talk slot at the 2025 R/Medicine conference to present the findings, as well as a $200 cash prize.\nFinalists will be required to present their project at the R/Medicine conference (must be prerecorded) on the afternoon of Thursday, June 12th, 2025.\n\n\n\n(TBD)\n\n\n\nBest overall: Daniel Gallardo Gomez, Andalusian Health Technology Assessment Department\nHonorable mention: Soham Sinha, University of Chicago\nHonrable mention: Mitchell Maltenfort, Children’s Hospital of Philadelphia"
  },
  {
    "objectID": "Competition.html#competition",
    "href": "Competition.html#competition",
    "title": "R/Medicine 2026",
    "section": "",
    "text": "University of Jos, Jos, Plateau State, Nigeria, Department of Community Medicine, MSc Field Epidemiology\n\n\n\n\nRSC Statistical Consulting, Statisticians\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe R/Medicine planning committee welcomes your participation in the virtual R/Medicine data challenge. Participants will have from now until Tuesday, May 20th, 2025 to work on submissions for the challenge. There will be 2 prizes: One $200 prize for the Student Division, and One $200 prize for the Professional Division, as well as a guaranteed spot for each division to present the findings at the 2025 R/Medicine conference. The quality of analyses/Quarto docs, as well as tables and visualizations will be considered.\nChanging attitudes towards vaccination in the US have significantly lowered childhood measles vaccination rates, as uptake of the recommended two doses of MMR vaccine before entering school has frequently fallen below the 95% recommended for community immunity.\n\n\n\nIn this data challenge, you will analyze MMR vaccination rates over time and by geographical area, as well as measles case rates and complications.\nWe ask that all analyses be done and submitted as Quarto documents. Participants can submit as an individual or as part of a team (but not both). The maximum team size is 3. Your goal will be to tell a data story about what is happening with measles immunity and outcomes in the US and the world in 2025.\nWe encourage you to use any and all of the public datasets available at: https://github.com/fbranda/measles. We encourage you to explore any of the csv files at the top level, as well as those in the measles/USA/data/ folder. Note that a lot of the contemporaneous files are updated each week, so be sure to use the latest data in your final submission.\nA special thank you to Francesco Branda, Adjunct professor of the Unit of Medical Statistics and Molecular Epidemiology at Campus Bio-Medico University of Rome, for creating and maintaining this valuable repository of measles data.\nAs this is an ongoing concern, datasets are being collected and updated in real time, ad we encourage you to document trends, use interactive formats like ggplotly and shiny-live, and to consider forecasting the future with tools like the {forecast} and {tidyverts} packages. One good reference for forecasting from Rob Hyndman can be found here.\nIn addition to the provided datasets on this Github site, you may request to use additional publicly available data in your submission by submitting a request (with the dataset) by April 29th, 2025 at 5:00PM ET. If approved, the dataset will be made available to all participants.\nYou will be evaluated by judges based on the relevance, completeness, and quality of your submission.\nJudges include:\nRaymond Balise, PhD, University of Miami\nPeter Higgins, MD, PhD, MSc, University of Michigan\nBryan P. Mayfield, PharmD, MS, Precision Analytical\n\n\n\nWhat is the growth rate of measles cases in the US vs Europe?\nAre there particular counties or states at risk due to low vaccination rates?\nHow are vaccination rates changing over time?\nWhat is your projection for the number of measles cases (and complications) in 2026?\n\n\n\n\n\nWhen: Now - May 20th, 2025 (submissions accepted through 11:59 PM ET)\nWhere: The R/Medicine data challenge is entirely virtual, with information and rules of the challenge available on this website. Updates will be posted on this website.\nWho you are: We welcome any participants over age 18, especially undergraduate students, graduate students, and early professional data scientists and biostatisticians. Analysts based in academic institutions, government statistical offices, think tanks, policy labs, and community organizations are encouraged to participate. Participants will be asked to submit to either the Student or Professional category, and we may request verification of eligibility for the student category.\nWhat topics you can explore: Participants can analyze the linked measles data sets in tandem with with any other related publicly available data submitted for approval before April 29th, 2025.\nSubmissions and evaluation: Participants will conduct their analyses and submit a short project narrative that describes the research question, analytic approach, and key findings. We encourage participants to find creative ways to incorporate tables, visualizations, and other aspects of data storytelling to create a compelling narrative. In addition to their completed analysis with the indicators they used, participants will be asked to submit documentation describing each step of their process. The documentation should be detailed enough as to make the project fully replicable. The narrative, methods, organization, and documentation of each participant’s project will be evaluated for relevance, completeness, and quality. More information on evaluation will be added to the FAQs section at the bottom of this page.\nNotification: Winners will be notified by Monday May 26th, and will be required to submit the pre-recorded talk on their findings by Monday June 2nd.\n\n\n\nSubmissions will be judged separately in the Student Division (any level of student, including graduate student) and Professional Division (any post-graduate level position). For each division, the prize will include a guaranteed regular talk slot at the 2025 R/Medicine conference to present the findings, as well as a $200 cash prize.\nFinalists will be required to present their project at the R/Medicine conference (must be prerecorded) on the afternoon of Thursday, June 12th, 2025.\n\n\n\n(TBD)\n\n\n\nBest overall: Daniel Gallardo Gomez, Andalusian Health Technology Assessment Department\nHonorable mention: Soham Sinha, University of Chicago\nHonrable mention: Mitchell Maltenfort, Children’s Hospital of Philadelphia"
  },
  {
    "objectID": "Program.html",
    "href": "Program.html",
    "title": "R/Medicine Schedule",
    "section": "",
    "text": "All times EDT\nThe conference runs in two parallel tracks for the first three days of workshops, demos, and panels\nThe talks on the final two days run in a single track\nClick the titles below to see additional details of each session\n\n\n\n\n\n\n\n\n\n\nWorkshop/Demo Day 1Monday, June 9, 2025\n\n\nStart Time\nEnd Time\nDuration\nTrack\n\n\n\n\n\n10:00 AM\n11:00 AM\n1h\nA\n\nDemo\nIn the Nix of Time: Creating a reproducible analytical environment with Nix and {rix}\nEric Nantz, Eli Lilly\n\n\n\n10:00 AM\n11:00 AM\n1h\nB\n\nDemo\nA framework for cohort building in R: the CohortConstructor package for data mapped to the OMOP Common Data Model\nNuria Mercade-Besora & Edward Burn, University of Oxford\n\n\n\n11:00 AM\n2:00 PM\n3h\nA\n\nWorkshop\nPromover la Equidad Científica: Una Introducción al uso de R para la programación en Bioestadística y Ciencia de Datos, en Español\nCatalina Canizares-Escobar & Francisco Cardozo, Florida International University\n\n\n\n11:00 AM\n2:00 PM\n3h\nB\n\nWorkshop\nIntroduction to R for Clinical Data\nStephan Kadauke and Rich Hanna, Children's Hospital of Philadelphia\n\n\n\n2:00 PM\n2:30 PM\n30m\n\n\nBreak\n\n\n\n\n\n2:30 PM\n5:30 PM\n3h\nA\n\nWorkshop\nR package development with GitHub Pages and pkgdown\nMelissa Van Bussel, Statistics Canada\n\n\n\n2:30 PM\n5:30 PM\n3h\nB\n\nWorkshop\nThe power of {targets} package for reproducible data science\nRahul Sangole, Apple\n\n\n\n5:30 PM\n6:30 PM\n1h\nA\n\nDemo\nREDCapSync and RosyREDCap: two development R packages using the REDCap API for standardized data pipelines and exploratory data analysis\nBrandon Rose, University of Miami/Jackson Memorial Hospital\n\n\n\n5:30 PM\n6:30 PM\n1h\nB\n\nDemo\nBiomarker Identification by Means of Frequent Itemset Mining and Contrast Set Mining\nPaul Kowalczyk, HAcKerS LaB\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop/Demo Day 2Tuesday, June 10, 2025\n\n\nStart Time\nEnd Time\nDuration\nTrack\n\n\n\n\n\n10:00 AM\n11:00 AM\n1h\nA\n\nDemo\nUsing R shiny to perform and automate decision-analytic modeling for cost-effectiveness analysis\nMahip Acharya, University of Arkansas for Medical Sciences\n\n\n\n10:00 AM\n11:00 AM\n1h\nB\n\nDemo\nVisualising data for patients: create accessible charts\nRita Giordano, Visual data Studio\n\n\n\n11:00 AM\n2:00 PM\n3h\nA\n\nWorkshop\nSurvival analysis with tidymodels\nHannah Frick, Posit\n\n\n\n11:00 AM\n2:00 PM\n3h\nB\n\nWorkshop\nFirst Steps with SQL in R: Making Data Talk\nChris Battiston, Women's College Hospital\n\n\n\n2:00 PM\n2:30 PM\n30m\n\n\nBreak\n\n\n\n\n\n2:30 PM\n5:30 PM\n3h\nA\n\nWorkshop\n'Visualise, Optimise, Parameterise!' - Writing dataviz code that your future self will thank you for\nCara Thompson\n\n\n\n2:30 PM\n3:30 PM\n1h\nB\n\nDemo\nQuarto Dashboards: from zero to publish in one hour\nMine Çetinkaya-Rundel, Duke University + Posit PBC\n\n\n\n3:30 PM\n4:30 PM\n1h\nB\n\nPanel\nSupporting R learners on the job during interesting times: A panel of R educators\nRay Balise, Silvia Canelón, Meghan Harris, Ted Laderas, Joy Payton\n\n\n\n4:30 PM\n5:30 PM\n1h\nB\n\nDemo\nR You Compliant? Validating Packages for Regulatory Readiness\nChris Battiston, Women's College Hospital\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop/Demo Day 3Wednesday, June 11, 2025\n\n\nStart Time\nEnd Time\nDuration\nTrack\n\n\n\n\n\n10:00 AM\n11:00 AM\n1h\nA\n\nDemo\nApplication of attention mechanism to improve performance of surveyed llm/mllm used across R/Medicine\nRobert Devine, Johnson & Johnson Companies\n\n\n\n10:00 AM\n11:00 AM\n1h\nB\n\nDemo\nCo-occurrence analysis and knowledge graphs for suicide risk prediction\nThomas Charlon, Harvard Medical School\n\n\n\n11:00 AM\n2:00 PM\n3h\nA\n\nWorkshop\nRix: reproducible data science environments with Nix\nBruno Rodrigues, Luxembourg’s Ministry of Research and Higher Education\n\n\n\n11:00 AM\n2:00 PM\n3h\nB\n\nWorkshop\nPersonal R Administration\nDavid Aja, Posit;, Shannon Pileggi, The Prostate Cancer Clinical Trials Consortium\n\n\n\n2:00 PM\n2:30 PM\n30m\n\n\nBreak\n\n\n\n\n\n2:30 PM\n5:30 PM\n3h\nA\n\nWorkshop\nDemystifying LLMs with Ellmer\nJoe Cheng, Posit\n\n\n\n2:30 PM\n5:30 PM\n3h\nB\n\nWorkshop\nteal Mastery: From Pre-built Modules to Custom Module Creation\nDony Unardi, Genentech\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting Day 1Thursday, June 12, 2025\n\n\nStart Time\nEnd Time\nDuration\n\n\n\n\n\n11:00 AM\n11:15 AM\n15m\n\nOpening Remarks\n\nEmily Zabor, Cleveland Clinic\n\n\n\n11:15 AM\n12:15 PM\n1h\n\nKeynote\nReinventing medicine with AI\nZiad Obermeyer, UC Berkeley\n\n\n\n12:17 PM\n12:37 PM\n20m\n\nRegular Talk\nRetrospective clinical data harmonisation reporting using R and Quarto\nJeremy Selva, National Heart Centre Singapore\n\n\n\n12:39 PM\n12:59 PM\n20m\n\nRegular Talk\nUnlocking Statistical Consistency Across Platforms: The CAMIS Project\nChristina Fillmore and Lyn Taylor, Parexel\n\n\n\n1:01 PM\n1:21 PM\n20m\n\nRegular Talk\nSupercharging Statistical Analysis with ARDs and the {cards} R Package\nBecca Krouse and Davide Garolini, GSK/Roche\n\n\n\n1:23 PM\n1:43 PM\n20m\n\nRegular Talk\nValidating Shiny Apps in Regulated Environments\nPedro Silva, Jumping Rivers\n\n\n\n1:45 PM\n1:55 PM\n10m\n\nLightning Talk\nImproving Reproducibility of Medical Research with Controlled Vocabularies\nJonathan Pearce, Analysis Group\n\n\n\n1:57 PM\n2:12 PM\n15m\n\nBreak\n\n\n\n\n\n2:12 PM\n2:32 PM\n20m\n\nRegular Talk\nMix, Pour, Share: The rUM Cocktail for Biomedical Project Packaging\nKyle Grealis and Raymond Balise, University of Miami\n\n\n\n2:34 PM\n2:54 PM\n20m\n\nRegular Talk\nRefactor or Preserve? Challenging the 'If It Ain’t Broken, Don’t Fix It' Mindset in Shiny App Lifecycle\nDror Berel, Independent consultant\n\n\n\n2:56 PM\n3:16 PM\n20m\n\nRegular Talk\nNo More Copy-Paste: Automating Patient Inquiry Tracking in Pharma with Shiny\nTanya Cashorali, TCB Analytics\n\n\n\n3:18 PM\n3:28 PM\n10m\n\nLightning Talk\nPreprocessing Electronic Health Records for Analysis-Ready Data in an Asthma Cohort\nKimberly Lactaoen, University of Pennsylvania\n\n\n\n3:30 PM\n3:50 PM\n20m\n\nRegular Talk\nRHealth – A Deep Learning Toolkit for Healthcare Predictive Modeling\nJunyi Gao, University of Edinburgh\n\n\n\n3:52 PM\n4:12 PM\n20m\n\nRegular Talk\nDengue Forecasting Addressing the Interrupted Effect from COVID-19 Cases\nThiyanga Talagala, University of Sri Jayewardeneoura\n\n\n\n4:14 PM\n4:24 PM\n10m\n\nLightning Talk\nProfessional competition winner\nHarrison Plate & Shonushka Sawant, RSC Statistical Consulting\n\n\n\n4:26 PM\n4:36 PM\n10m\n\nLightning Talk\nStudent competition winner\nIko Musa, University of Jos, Nigeria\n\n\n\n4:38 PM\n4:43 PM\n5m\n\nClosing remarks\n\nPeter Higgins, University of Michigan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting Day 2Friday, June 13, 2025\n\n\nStart Time\nEnd Time\nDuration\n\n\n\n\n\n11:00 AM\n11:15 AM\n15m\n\nOpening Remarks\n\nEmily Zabor, Cleveland Clinic\n\n\n\n11:15 AM\n12:15 PM\n1h\n\nKeynote\nModel Evaluation: From Machine Learning to Generative AI\nErin LeDell, Distributional Inc\n\n\n\n12:17 PM\n12:27 PM\n10m\n\nLightning Talk\nriskcalc.org: A Repository of Risk Calculators for Medical Decision Making\nAlex Zajichek, Cleveland Clinic\n\n\n\n12:29 PM\n12:49 PM\n20m\n\nRegular Talk\nnonprobsvy -- An R package for modern methods for non-probability survey\nMaciej Beręsewicz, Poznań University of Economics and Business / Statistical Office in Poznań (Poland)\n\n\n\n12:51 PM\n1:01 PM\n10m\n\nLightning Talk\nrainbowR: A community for LGBTQ+ folks who code in R\nElla Kaye, University of Warwick\n\n\n\n1:03 PM\n1:23 PM\n20m\n\nRegular Talk\nAn Accelerometry Biomarker Framework with Application in Vigilance in UK Biobank Data\nMichael Kane, MD Anderson Cancer Center\n\n\n\n1:25 PM\n1:35 PM\n10m\n\nLightning Talk\npretestcad: An R package to calculate PreTest Probability (PTP) scores for obstructive Coronary Artery Disease (CAD)\nJeremy Selva, National Heart Centre Singapore\n\n\n\n1:37 PM\n1:47 PM\n10m\n\nLightning Talk\nAOUSDOHtools: An R Package for Social Determinants of Health Survey data in the All of Us Research Program\nZhirui Deng, University of Pittsburgh, School of Nursing\n\n\n\n1:49 PM\n2:09 PM\n20m\n\nRegular Talk\nMIIPW: An R package for Generalized Estimating Equations with missing data integration using a combination of mean score and inverse probability weighted approaches and multiple imputation\nBhrigu Rajbongshi, Indian Institute of Technology(Indian School of Mines) Dhanbad\n\n\n\n2:11 PM\n2:31 PM\n20m\n\nRegular Talk\nkidney.epi R Package for Facilitating Research in Diabetes, Kidney, Heart, and Other Diseases\nBoris Bikbov, Scientific-Tools.Org\n\n\n\n2:33 PM\n2:43 PM\n10m\n\nLightning Talk\nExamining Factors Associated with Depressive Severity Among Cancer Survivors: An Analysis of the National Health Interview Survey\nAndre Williams, Florida Atlantic University\n\n\n\n2:45 PM\n3:00 PM\n15m\n\nBreak\n\n\n\n\n\n3:00 PM\n3:20 PM\n20m\n\nRegular Talk\n{redquack}: An R Package for Memory Efficient REDCap-to-DuckDB Workflows\nDylan Pieper, University of Pittsburgh\n\n\n\n3:22 PM\n3:32 PM\n10m\n\nLightning Talk\nOptimizing Public Healthcare Cost Recovery with R: A Use Case from Argentina\nAriana Bardauil and Dacio Martinez, Ministry of health - Buenos Aires City Government\n\n\n\n3:34 PM\n3:44 PM\n10m\n\nLightning Talk\nSwimmer Plots with ggswim\nRichard Hanna, Children's Hospital of Philadelphia\n\n\n\n3:46 PM\n3:56 PM\n10m\n\nLightning Talk\nWhat to Do When Shiny Packages Don't Fully Support Your Idea\nAnastasiia Kostiv, ESQlabs\n\n\n\n3:58 PM\n4:08 PM\n10m\n\nLightning Talk\nBootstrap inference made easy: p-values and confidence intervals in one line of code\nMåns Thulin, Thulin Consulting AB\n\n\n\n4:10 PM\n4:20 PM\n10m\n\nLightning Talk\nEthical Considerations of Contrasts in Statistical Modeling of Medical Equity\nDwight Barry and Nicole Chicoine, Seattle Children’s Hospital\n\n\n\n4:22 PM\n4:32 PM\n10m\n\nLightning Talk\nAdvanced Distance Metrics for High-Dimensional Clustering: introducing 'distanceHD' R-package\nJung Ae Lee, University of Massachusetts Chan Medical School\n\n\n\n4:34 PM\n4:54 PM\n20m\n\nRegular Talk\nUnified Deep Learning Survival Analysis for Competing Risk Modeling with Functional Covariates and Missing Data Imputation\nYan Zou, Cleveland Clinic\n\n\n\n4:56 PM\n5:01 PM\n5m\n\nClosing Remarks\n\nMichael Kane, MD Anderson Cancer Center"
  },
  {
    "objectID": "Committees.html",
    "href": "Committees.html",
    "title": "Committees for R/Medicine 2026",
    "section": "",
    "text": "Chair: Emily Zabor, Cleveland Clinic\nTerry Christiani, The R Consortium\nSteven Schwager, Cornell University\nRay Balise, University of Miami\nBeth Atkinson, Mayo Clinic\nMichael Kane, MD Anderson\nDaniel Chen, The University of BC & Posit\nAndey Nunes-Brewster, Oregon Health Authority\nBen Gerber, UMass Chan\nDaniel Sjoberg, Genentech\nRichard Hanna, Children’s Hospital of Philadelphia\nHenry Ugorji, Oregon Health Authority\nBrandon Rose, University of Texas Southwestern Medical Center\nCatalina Canizares-Escobar, New York University\nFrancisco Cardozo Macias, University of Miami\nAndie Hendrick, Oregon Health Authority\n\n\n\n\n\n\n\nTBD"
  },
  {
    "objectID": "Committees.html#organizing-committee",
    "href": "Committees.html#organizing-committee",
    "title": "Committees for R/Medicine 2026",
    "section": "",
    "text": "Chair: Emily Zabor, Cleveland Clinic\nTerry Christiani, The R Consortium\nSteven Schwager, Cornell University\nRay Balise, University of Miami\nBeth Atkinson, Mayo Clinic\nMichael Kane, MD Anderson\nDaniel Chen, The University of BC & Posit\nAndey Nunes-Brewster, Oregon Health Authority\nBen Gerber, UMass Chan\nDaniel Sjoberg, Genentech\nRichard Hanna, Children’s Hospital of Philadelphia\nHenry Ugorji, Oregon Health Authority\nBrandon Rose, University of Texas Southwestern Medical Center\nCatalina Canizares-Escobar, New York University\nFrancisco Cardozo Macias, University of Miami\nAndie Hendrick, Oregon Health Authority"
  },
  {
    "objectID": "Committees.html#program-committee",
    "href": "Committees.html#program-committee",
    "title": "Committees for R/Medicine 2026",
    "section": "",
    "text": "TBD"
  },
  {
    "objectID": "Committees.html#past-chairs",
    "href": "Committees.html#past-chairs",
    "title": "Committees for R/Medicine 2026",
    "section": "Past chairs",
    "text": "Past chairs\nMichael Kane, MD Anderson. Organizing committee and Program committee chair: 2018, 2019\nStephan Kadauke, Children’s Hospital of Philadelphia. Organizing committee chair: 2020, 2021, 2022\nBeth Atkinson, Mayo Clinic. Program committee chair: 2020\nSteven Schwager, Cornell University. Program committee chair: 2021, 2022, 2023, 2024\nPeter Higgins, University of Michigan. Organizing committee chair: 2023, 2024"
  }
]